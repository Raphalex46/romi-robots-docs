{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"In this document you will find information on how to use and build the ROMI robots Official Website Link ROMI is an H2020 European project: Official Website . GitHub sources Link For now these sources are privates. Project funding Link This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement No 773875.","title":"Home"},{"location":"#official-website","text":"ROMI is an H2020 European project: Official Website .","title":"Official Website"},{"location":"#github-sources","text":"For now these sources are privates.","title":"GitHub sources"},{"location":"#project-funding","text":"This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement No 773875.","title":"Project funding"},{"location":"Cable/","text":"Wirebot Link Main Board and Eletronics Link Raspberry Pi - packages, Dependencies and Configurations Link Download the image Robotics Ubuntu+ROS Raspberry Pi Image (3B+ Support) that comes with Ubuntu 16.04 (LXDE), and ROS Kinetic. Copy the image to the SD card. Instructions here. Resizes the file system to fill the SD card before booting following this instructions. Acces to the raspi-config utility: $computer :~ $sudo raspi-config Choose \"Expand root partition to fill SD card\" option: The Ubiquityrobotics images come up as a Wifi acces point. The SSID is ubiquityrobotXXXX where XXXX is part of the MAC address. Connect to the wifi hostopost and use folowing wifi password: robotseverywhere Once connected, it is possible to log into the Pi with ssh ubuntu@10.42.0.1 with the following password of: ubuntu Desable the default robots and node runing on the pi. $ ubuntu@ubiquityrobot.local: $sudo systemctl disable magni-base Raspberry Pi - Setting up the WIREDBOT to the Network Link Open a new terminal window, and log in to the robot with ssh: ATENTION : The HOSTNAME for firts time is \u201cubiquityrobot.local\u201d. $ computer:~ $ssh ubuntu@ubiquityrobot.local ATENTION : The password for firts time is \u201cubuntu\u201d. Change the hostname using pifi. Type the following command: $ ubuntu@ubiquityrobot.local:~ $sudo pifi set-hostname wiredbot Reboot the Pi. $ ubuntu@ubiquityrobot.local:~ $sudo reboot Log in to the robot with the new hostname \"wiredbot\": $ computer:~ $ssh ubuntu@wiredbot.local Use pifi to list the nearby networks: $ ubuntu@wiredbot:~ $pifi list seen ATENTION : Search for the network where the robots are connected. Swich to to the desire network by using the following command. $ ubuntu@NEWHOSTNAME:~ $sudo pifi add localNetwork password ATTENTION : The keyword \"localNetwork\" on this documentation refert to the network the robot need to be connected. The keyword \"pass\" on this documentation refer to the password of the network. Reboot the Pi. $ ubuntu@wiredbot:~ $sudo reboot Test the connectivity with the Pi. Open a new terminal window on a external on a diferent computer: $ computer:~ $ping wirebot.local TIP : Press control-c to stop the pinging ADVERTENCE : If something goes wrong, the PI will come back up as access point mode. Search on the network for the name ubiquityrobot, reboot and start over. Log into the PI by using: $ computer:~ $ssh ubuntu@wirebot.local the output will be: The authenticity of host \u201810.0.0.113 ( 10 .0.0.113 ) \u2019 can\u2019t be established. ECDSA key fingerprint is SHA256:sDDeGZzL8FPY3kMmvhwjPC9wH+mGsAxJL/dNXpoYnsc. Are you sure you want to continue connecting ( yes/no ) ? continue by wrinting: $ computer:~ $yes the password is still. ubuntu Update and updagrade de Pi. $ ubuntu@wiredbot:~ $sudo apt-get update $ ubuntu@wiredbot:~ $sudo apt-get upgrade ROS - Setting up the ROS NODES and Arduino Firmware. Link Make sure you have installed the resent updates and updagrades. $ ubuntu@wiredbot:~ $sudo apt-get update $ ubuntu@wiredbot:~ $sudo apt-get upgrade Point to the workspace folder for ros packages Clone the repository on the Pi, the romi/grlbl_serial into the /src folder of your catkin workspace and rebuild your workspace: $ ubuntu@wiredbot:~ $cd ~/catkin_ws/src/ $ ubuntu@wiredbot:~ $git clone git@github.com:romi/grlbl_serial.git $ ubuntu@wiredbot:~ $catkin_make Clone the repository on the Pi, the romi/i2c_pca9685_driver into the /src folder of your catkin workspace and rebuild your workspace: $ ubuntu@wiredbot:~ $cd ~/catkin_ws/src/ $ ubuntu@wiredbot:~ $git clone git@github.com:romi/i2c_pca9685_driver.git $ ubuntu@wiredbot:~ $catkin_make Wiring diagram. Link Schematics: List Part Item Description Quantity 0 Raspberry pi model 3b+ 1 1 Raspberry Pi Camera Module v2 1 2 16-Channel 12-bit - I2C interface - PCA9685 1 3 Arduino UNO 1 4 Arduino CNC Shield V3 1 5 A4988 Stepper Motor Driver 4 6 Nema 23 Unipolar 1.8deg 1 7 Survey3W Camera - Orange+Cyan+NIR (OCN, NDVI) 1 8 Survey3W HDMI PWM Trigger Cable 1 9 Survey3 Advanced GPS Receiver 1 10 12V Power Supply 1 11 Wires and general hardware - Hardware Setup. Link 1.Drawings * Assebly drawing - Top view * Assebly drawing - Botton View List Part Item Description Quantity 0 Aluminium Profile 20\u00d720 T-Slot 5 4 1 Idler Pulley Plate 6 2 Join Plat T 4 3 Corner connector 90 degree (V-Slot) 2 4 Gantry Plate V-Slot 20-80 2 5 3M Drop in Tee Nuts \u2013 Insert nuts 50 6 3M Allen Low Profile Screws 50 7 M8 Allen Screw - 45mm Long 6 8 Motor Mount Plate NEMA 23 1 9 Nylon Pulley And Wheel - 40 mm Diameter - 8 mm Bearing 6 10 Nema 23 stepper motor 1 11 P65 Weatherproof Enclosure/electrical enclosure box 2 12 5mm Shock Cord - Marine Grade Polyester Coated Rubber Rope - Running ROS node - Path Planning Link ROS Nodes Overview. ROS Master - Run ROS Nodes over the raspberry PI. Log into the raspberry PI by using: $ computer:~ $ssh ubuntu@wirebot.local (OPTIONAL) Edit the path planning according to the dimensions of the field to scan and the desired length and amount of waypoints. $ ubuntu@ubiquityrobot.local:~ $sudo nano ~/catkin_ws/src/grlbl_serial/src/path_planning_action_client.py * Edit the path_planning_action_client.py by changing the variable movement_goal.xyz_position that is under the function def path_planning_client() . Here is an example of a Path planning that takes pictures of every 500mm in a distance of 10mts: movement_goal . xyz_position = [ { x :0, y :0, z :500, delay :20} , { x :0, y :0, z :1000, delay :20} , { x :0, y :0, z :1500, delay :20} , { x :0, y :0, z :2000, delay :20} , { x :0, y :0, z :2500, delay :20} , { x :0, y :0, z :3000, delay :20} , { x :0, y :0, z :3500, delay :20} , { x :0, y :0, z :4000, delay :20} , { x :0, y :0, z :4500, delay :20} , { x :0, y :0, z :5000, delay :20} , { x :0, y :0, z :5500, delay :20} , { x :0, y :0, z :6000, delay :20} , { x :0, y :0, z :6500, delay :20} , { x :0, y :0, z :7000, delay :20} , { x :0, y :0, z :7500, delay :20} , { x :0, y :0, z :8000, delay :20} , { x :0, y :0, z :8500, delay :20} , { x :0, y :0, z :9000, delay :20} , { x :0, y :0, z :9500, delay :20} ] Start up the nodes and the ROS master by launching the path_planning_action_server_node node under the raspberry PI: $ ubuntu@ubiquityrobot.local:~ $roslaunch grlbl_serial path_planning_action_server_node.launch (ADVERTENCE) If the ROS package is not under the autocomplete method of the terminal. The problem will be solve by sourcing the devel/setup.bash. $ ubuntu@ubiquityrobot.local:~ $source ~/catkin_ws/src/devel/setup.bash 3. ROS Slave - Run ROS Nodes over the Remote Computer. Start up the nodes by launching the path_planning_action_client_node node under the remote computer: $ ubuntu@ubiquityrobot.local:~ $roslaunch grlbl_serial path_planning_action_client_node.launch (OPTIONAL) This node as well can by launch over the raspberry PI. This can be done by lauching the node over a new terminal. By launching the previous ROS node on the WIREDBOT. The starting process of collecting photos from the Mapir camera and the Raspi Cam will be launch automatically according to the path planning instructions save on the path_planning_action_client.py file. Saving the data from the WIREDBOT. (UNDER-DEVELOPMENT) Link Kepp running or re start the node and the ROS master by launching the path_planning_action_server_node node under the raspberry PI: $ ubuntu@ubiquityrobot.local:~ $roslaunch grlbl_serial path_planning_action_server_node.launch Publish a 1500us to the /i2c_pca9685_driver wiredbot_PWMValues/wiredbot_PWMValues mapir_control_pwm: $ ubuntu@ubiquityrobot.local:~ $rostopic pub -1 /i2c_pca9685_driver wiredbot_PWMValues/wiredbot_PWMValues int16 mapir_control_pwm 1500 int16 motor_A_pwm int16 motor_B_pwm Once ros is publishing the message mapir_control_pwm 1500us under the topic \\i2c_pca9685_driver\\wiredbot_PWMValues. The camera is ready to mount. On the raspberry PI. Mount the camera by using the following commands. $ ubuntu@ubiquityrobot.local:~ $mkdir /mapir $ ubuntu@ubiquityrobot.local:~ $mkdir sudo mount -t vfat /dev/sdb2 /mapir $ ubuntu@ubiquityrobot.local:~ $cd /mapir/DCMI/Photos * Image Gallery - Valldaura: Link Lettuce Think and Wirebot: Wirebot on the field: Wirebot on the field: WIREBOT 3D Scans: Link","title":"Index"},{"location":"Cable/#wirebot","text":"","title":"Wirebot"},{"location":"Cable/#main-board-and-eletronics","text":"","title":"Main Board and Eletronics"},{"location":"Cable/#raspberry-pi-packages-dependencies-and-configurations","text":"Download the image Robotics Ubuntu+ROS Raspberry Pi Image (3B+ Support) that comes with Ubuntu 16.04 (LXDE), and ROS Kinetic. Copy the image to the SD card. Instructions here. Resizes the file system to fill the SD card before booting following this instructions. Acces to the raspi-config utility: $computer :~ $sudo raspi-config Choose \"Expand root partition to fill SD card\" option: The Ubiquityrobotics images come up as a Wifi acces point. The SSID is ubiquityrobotXXXX where XXXX is part of the MAC address. Connect to the wifi hostopost and use folowing wifi password: robotseverywhere Once connected, it is possible to log into the Pi with ssh ubuntu@10.42.0.1 with the following password of: ubuntu Desable the default robots and node runing on the pi. $ ubuntu@ubiquityrobot.local: $sudo systemctl disable magni-base","title":"Raspberry Pi - packages, Dependencies and Configurations"},{"location":"Cable/#raspberry-pi-setting-up-the-wiredbot-to-the-network","text":"Open a new terminal window, and log in to the robot with ssh: ATENTION : The HOSTNAME for firts time is \u201cubiquityrobot.local\u201d. $ computer:~ $ssh ubuntu@ubiquityrobot.local ATENTION : The password for firts time is \u201cubuntu\u201d. Change the hostname using pifi. Type the following command: $ ubuntu@ubiquityrobot.local:~ $sudo pifi set-hostname wiredbot Reboot the Pi. $ ubuntu@ubiquityrobot.local:~ $sudo reboot Log in to the robot with the new hostname \"wiredbot\": $ computer:~ $ssh ubuntu@wiredbot.local Use pifi to list the nearby networks: $ ubuntu@wiredbot:~ $pifi list seen ATENTION : Search for the network where the robots are connected. Swich to to the desire network by using the following command. $ ubuntu@NEWHOSTNAME:~ $sudo pifi add localNetwork password ATTENTION : The keyword \"localNetwork\" on this documentation refert to the network the robot need to be connected. The keyword \"pass\" on this documentation refer to the password of the network. Reboot the Pi. $ ubuntu@wiredbot:~ $sudo reboot Test the connectivity with the Pi. Open a new terminal window on a external on a diferent computer: $ computer:~ $ping wirebot.local TIP : Press control-c to stop the pinging ADVERTENCE : If something goes wrong, the PI will come back up as access point mode. Search on the network for the name ubiquityrobot, reboot and start over. Log into the PI by using: $ computer:~ $ssh ubuntu@wirebot.local the output will be: The authenticity of host \u201810.0.0.113 ( 10 .0.0.113 ) \u2019 can\u2019t be established. ECDSA key fingerprint is SHA256:sDDeGZzL8FPY3kMmvhwjPC9wH+mGsAxJL/dNXpoYnsc. Are you sure you want to continue connecting ( yes/no ) ? continue by wrinting: $ computer:~ $yes the password is still. ubuntu Update and updagrade de Pi. $ ubuntu@wiredbot:~ $sudo apt-get update $ ubuntu@wiredbot:~ $sudo apt-get upgrade","title":"Raspberry Pi - Setting up the WIREDBOT to the Network"},{"location":"Cable/#ros-setting-up-the-ros-nodes-and-arduino-firmware","text":"Make sure you have installed the resent updates and updagrades. $ ubuntu@wiredbot:~ $sudo apt-get update $ ubuntu@wiredbot:~ $sudo apt-get upgrade Point to the workspace folder for ros packages Clone the repository on the Pi, the romi/grlbl_serial into the /src folder of your catkin workspace and rebuild your workspace: $ ubuntu@wiredbot:~ $cd ~/catkin_ws/src/ $ ubuntu@wiredbot:~ $git clone git@github.com:romi/grlbl_serial.git $ ubuntu@wiredbot:~ $catkin_make Clone the repository on the Pi, the romi/i2c_pca9685_driver into the /src folder of your catkin workspace and rebuild your workspace: $ ubuntu@wiredbot:~ $cd ~/catkin_ws/src/ $ ubuntu@wiredbot:~ $git clone git@github.com:romi/i2c_pca9685_driver.git $ ubuntu@wiredbot:~ $catkin_make","title":"ROS - Setting up the ROS NODES and Arduino Firmware."},{"location":"Cable/#wiring-diagram","text":"Schematics: List Part Item Description Quantity 0 Raspberry pi model 3b+ 1 1 Raspberry Pi Camera Module v2 1 2 16-Channel 12-bit - I2C interface - PCA9685 1 3 Arduino UNO 1 4 Arduino CNC Shield V3 1 5 A4988 Stepper Motor Driver 4 6 Nema 23 Unipolar 1.8deg 1 7 Survey3W Camera - Orange+Cyan+NIR (OCN, NDVI) 1 8 Survey3W HDMI PWM Trigger Cable 1 9 Survey3 Advanced GPS Receiver 1 10 12V Power Supply 1 11 Wires and general hardware -","title":"Wiring diagram."},{"location":"Cable/#hardware-setup","text":"1.Drawings * Assebly drawing - Top view * Assebly drawing - Botton View List Part Item Description Quantity 0 Aluminium Profile 20\u00d720 T-Slot 5 4 1 Idler Pulley Plate 6 2 Join Plat T 4 3 Corner connector 90 degree (V-Slot) 2 4 Gantry Plate V-Slot 20-80 2 5 3M Drop in Tee Nuts \u2013 Insert nuts 50 6 3M Allen Low Profile Screws 50 7 M8 Allen Screw - 45mm Long 6 8 Motor Mount Plate NEMA 23 1 9 Nylon Pulley And Wheel - 40 mm Diameter - 8 mm Bearing 6 10 Nema 23 stepper motor 1 11 P65 Weatherproof Enclosure/electrical enclosure box 2 12 5mm Shock Cord - Marine Grade Polyester Coated Rubber Rope -","title":"Hardware Setup."},{"location":"Cable/#running-ros-node-path-planning","text":"ROS Nodes Overview. ROS Master - Run ROS Nodes over the raspberry PI. Log into the raspberry PI by using: $ computer:~ $ssh ubuntu@wirebot.local (OPTIONAL) Edit the path planning according to the dimensions of the field to scan and the desired length and amount of waypoints. $ ubuntu@ubiquityrobot.local:~ $sudo nano ~/catkin_ws/src/grlbl_serial/src/path_planning_action_client.py * Edit the path_planning_action_client.py by changing the variable movement_goal.xyz_position that is under the function def path_planning_client() . Here is an example of a Path planning that takes pictures of every 500mm in a distance of 10mts: movement_goal . xyz_position = [ { x :0, y :0, z :500, delay :20} , { x :0, y :0, z :1000, delay :20} , { x :0, y :0, z :1500, delay :20} , { x :0, y :0, z :2000, delay :20} , { x :0, y :0, z :2500, delay :20} , { x :0, y :0, z :3000, delay :20} , { x :0, y :0, z :3500, delay :20} , { x :0, y :0, z :4000, delay :20} , { x :0, y :0, z :4500, delay :20} , { x :0, y :0, z :5000, delay :20} , { x :0, y :0, z :5500, delay :20} , { x :0, y :0, z :6000, delay :20} , { x :0, y :0, z :6500, delay :20} , { x :0, y :0, z :7000, delay :20} , { x :0, y :0, z :7500, delay :20} , { x :0, y :0, z :8000, delay :20} , { x :0, y :0, z :8500, delay :20} , { x :0, y :0, z :9000, delay :20} , { x :0, y :0, z :9500, delay :20} ] Start up the nodes and the ROS master by launching the path_planning_action_server_node node under the raspberry PI: $ ubuntu@ubiquityrobot.local:~ $roslaunch grlbl_serial path_planning_action_server_node.launch (ADVERTENCE) If the ROS package is not under the autocomplete method of the terminal. The problem will be solve by sourcing the devel/setup.bash. $ ubuntu@ubiquityrobot.local:~ $source ~/catkin_ws/src/devel/setup.bash 3. ROS Slave - Run ROS Nodes over the Remote Computer. Start up the nodes by launching the path_planning_action_client_node node under the remote computer: $ ubuntu@ubiquityrobot.local:~ $roslaunch grlbl_serial path_planning_action_client_node.launch (OPTIONAL) This node as well can by launch over the raspberry PI. This can be done by lauching the node over a new terminal. By launching the previous ROS node on the WIREDBOT. The starting process of collecting photos from the Mapir camera and the Raspi Cam will be launch automatically according to the path planning instructions save on the path_planning_action_client.py file.","title":"Running ROS node - Path Planning"},{"location":"Cable/#saving-the-data-from-the-wiredbot-under-development","text":"Kepp running or re start the node and the ROS master by launching the path_planning_action_server_node node under the raspberry PI: $ ubuntu@ubiquityrobot.local:~ $roslaunch grlbl_serial path_planning_action_server_node.launch Publish a 1500us to the /i2c_pca9685_driver wiredbot_PWMValues/wiredbot_PWMValues mapir_control_pwm: $ ubuntu@ubiquityrobot.local:~ $rostopic pub -1 /i2c_pca9685_driver wiredbot_PWMValues/wiredbot_PWMValues int16 mapir_control_pwm 1500 int16 motor_A_pwm int16 motor_B_pwm Once ros is publishing the message mapir_control_pwm 1500us under the topic \\i2c_pca9685_driver\\wiredbot_PWMValues. The camera is ready to mount. On the raspberry PI. Mount the camera by using the following commands. $ ubuntu@ubiquityrobot.local:~ $mkdir /mapir $ ubuntu@ubiquityrobot.local:~ $mkdir sudo mount -t vfat /dev/sdb2 /mapir $ ubuntu@ubiquityrobot.local:~ $cd /mapir/DCMI/Photos *","title":"Saving the data from the WIREDBOT. (UNDER-DEVELOPMENT)"},{"location":"Cable/#image-gallery-valldaura","text":"Lettuce Think and Wirebot: Wirebot on the field: Wirebot on the field:","title":"Image Gallery - Valldaura:"},{"location":"Cable/#wirebot-3d-scans","text":"","title":"WIREBOT 3D Scans:"},{"location":"Rover/","text":"In this document you will find information on how to use and build the ROMI Rover... User Manual Hardware Documentation Software Installation Developer Documentation","title":"Index"},{"location":"Rover/developer/","text":"Dev","title":"Developer Documentation"},{"location":"Rover/hardware/","text":"This document describes the hardware, both the mechanical parts and the electronics.. The main structure Link The figure below gives an overview of the main components. The mechanical components Link The frame Link The wheels Link The boxes Link The CNC Link We use currently use the X-Carve. Please follow X-Carve's documentation at . The Z-axis Link The cover Link The electronics Link The basic architecture of the control modules Link NOTE : The current rovers don't implements the schema above, yet: The CNC has no encoders. The rover in Valldaur doesn't have a control panel. The control panel Link NOTE : The control panel is still being developed at the time of writing. The control panel is used to start and stop the rover and to display status information on the character display. Component Specifications Example Controller Arduino Uno or equivalent Proto shield The shield allows you to solder the wires securely Adafruit Sparkfun Amazon Relay (2x) TODO Sparkfun Push button with LEDS (2x) One green and one red Adafruit LCD Character Display Comptable with XXX Farnell The power circuit Link NOTE : This is the new power circuit that will be used with the control panel. It's currently not implemented in either rover. There are three separate power circuits: Always-on circuit : This circuits powers the control panel. Logic circuit : This circuits powers the embedded PC and other control circuits. Power circuit : This circuit drives all the motors. This is the circuit that is cut when the security switch (the big red button) is pressed. The control panel actuates two relays (Relay 1 2) according to the two start-up phases (the PC and the logic circuits start up first, then the motors are powered up). The third relay is designed to handle strong currents. It has a protection against sparks and back-currents. Most of the logic runs on 5V. (TODO: Add a Meanwell power converter. Q: One converter for the the control panel + one of the logic circuit? Or one single converter?) The figure does not show the power line for the weeding hoe. The hoe is turned on/off using a fourth relay that is connected to the gShield board of the CNC. It using the CNC's spindle on/off functionality. You can find more information on this in the section on the CNC below. Component Specifications Example Relay Non-Latching, protection against sparks and back-current (TODO: be more precise) RS Online Security switch Farnell: button and housing The navigation module Link The navigation uses a differential wheel drive, with two motorized wheels in the back and two swivel caster in the front. This makes the control fairly straight-forward and the components are easy to source. The navigation module can also receive input from a remote control to steer the rover. The main components are shown below: Components Link Component Specifications Example Motors Brushed DC motors , 24 V, minimum 200 W We are using wheel chair motors for now. We bought a set at Superdroid Robots . Encoders Incremental encoders US Digital E2 (Available from Superdroid Robotics ). Controller Arduino Uno or equivalent Proto shield The shield allows you to solder the wires securely Adafruit Sparkfun Amazon Motor driver Preferably one board that can drive two motors. Two drivers, one for each motor, is possible, too. Power input: 24V, Maximum output current: 15 A per motor, Control signals: two PWM signals (similar to RC input) for the left and right motor. The driver implements a standard H-bridge to control to power supplied to the motors (both forward and backward rotation). Sabertooth 2x60A Sabertooth 2x32A RoboClaw 2x60A RC controller and receiver A standard RC receiver that outputs a PWM signal. Powered by 5V. We've succesfully used the remote controllers for Spektrum , this one for example or similar Wheels You will need those, too. We are using the wheel provided by Superdroid Robotics for now Wiring diagram Link The tool positioning Link A CNC is adapted for use in the rover. We replaced the spindle that is normally used to carve wooden pieces, with a rotating weeding hoe. We are using to larger, 1000 mm sized version of the X-Carve . The newer X-Carve uses a custom design board for the control. However, we prefer using the older solution that combines an Arduino Uno with a gShield because it is smaller and more generic. For the time being, we use the grbl language to send commands from the embedded PC to the CNC controller. Therefore, any solution that accepts grbl commands should be drop-in solution for the Uno+gShield combo. Component Specifications Example CNC Minimum work area: 0.7 m x 0.7m X-Carve Optional: Controller board Must run grbl interpreter Arduino Uno Optional: Stepper drivers (3 steppers) The driver must use the STEP/DIR control signals gShield [Arduino CNC Shield] eBay and RepRap You can still have a look at XCarve's older documentation on how to wire the controller boards: http://x-carve-instructions.inventables.com/xcarve2015/step10/ http://x-carve-instructions.inventables.com/xcarve2015/step14/ Notable, the following two diagrams are of interest: The yellow wire marked \"spinle\" in the image above is used to turn the weeding hoe on or off, as shown in the figure below (see also the figure in the section on the power circuit).","title":"Hardware Documentation"},{"location":"Rover/hardware/#the-main-structure","text":"The figure below gives an overview of the main components.","title":"The main structure"},{"location":"Rover/hardware/#the-mechanical-components","text":"","title":"The mechanical components"},{"location":"Rover/hardware/#the-frame","text":"","title":"The frame"},{"location":"Rover/hardware/#the-wheels","text":"","title":"The wheels"},{"location":"Rover/hardware/#the-boxes","text":"","title":"The boxes"},{"location":"Rover/hardware/#the-cnc","text":"We use currently use the X-Carve. Please follow X-Carve's documentation at .","title":"The CNC"},{"location":"Rover/hardware/#the-z-axis","text":"","title":"The Z-axis"},{"location":"Rover/hardware/#the-cover","text":"","title":"The cover"},{"location":"Rover/hardware/#the-electronics","text":"","title":"The electronics"},{"location":"Rover/hardware/#the-basic-architecture-of-the-control-modules","text":"NOTE : The current rovers don't implements the schema above, yet: The CNC has no encoders. The rover in Valldaur doesn't have a control panel.","title":"The basic architecture of the control modules"},{"location":"Rover/hardware/#the-control-panel","text":"NOTE : The control panel is still being developed at the time of writing. The control panel is used to start and stop the rover and to display status information on the character display. Component Specifications Example Controller Arduino Uno or equivalent Proto shield The shield allows you to solder the wires securely Adafruit Sparkfun Amazon Relay (2x) TODO Sparkfun Push button with LEDS (2x) One green and one red Adafruit LCD Character Display Comptable with XXX Farnell","title":"The control panel"},{"location":"Rover/hardware/#the-power-circuit","text":"NOTE : This is the new power circuit that will be used with the control panel. It's currently not implemented in either rover. There are three separate power circuits: Always-on circuit : This circuits powers the control panel. Logic circuit : This circuits powers the embedded PC and other control circuits. Power circuit : This circuit drives all the motors. This is the circuit that is cut when the security switch (the big red button) is pressed. The control panel actuates two relays (Relay 1 2) according to the two start-up phases (the PC and the logic circuits start up first, then the motors are powered up). The third relay is designed to handle strong currents. It has a protection against sparks and back-currents. Most of the logic runs on 5V. (TODO: Add a Meanwell power converter. Q: One converter for the the control panel + one of the logic circuit? Or one single converter?) The figure does not show the power line for the weeding hoe. The hoe is turned on/off using a fourth relay that is connected to the gShield board of the CNC. It using the CNC's spindle on/off functionality. You can find more information on this in the section on the CNC below. Component Specifications Example Relay Non-Latching, protection against sparks and back-current (TODO: be more precise) RS Online Security switch Farnell: button and housing","title":"The power circuit"},{"location":"Rover/hardware/#the-navigation-module","text":"The navigation uses a differential wheel drive, with two motorized wheels in the back and two swivel caster in the front. This makes the control fairly straight-forward and the components are easy to source. The navigation module can also receive input from a remote control to steer the rover. The main components are shown below:","title":"The navigation module"},{"location":"Rover/hardware/#components","text":"Component Specifications Example Motors Brushed DC motors , 24 V, minimum 200 W We are using wheel chair motors for now. We bought a set at Superdroid Robots . Encoders Incremental encoders US Digital E2 (Available from Superdroid Robotics ). Controller Arduino Uno or equivalent Proto shield The shield allows you to solder the wires securely Adafruit Sparkfun Amazon Motor driver Preferably one board that can drive two motors. Two drivers, one for each motor, is possible, too. Power input: 24V, Maximum output current: 15 A per motor, Control signals: two PWM signals (similar to RC input) for the left and right motor. The driver implements a standard H-bridge to control to power supplied to the motors (both forward and backward rotation). Sabertooth 2x60A Sabertooth 2x32A RoboClaw 2x60A RC controller and receiver A standard RC receiver that outputs a PWM signal. Powered by 5V. We've succesfully used the remote controllers for Spektrum , this one for example or similar Wheels You will need those, too. We are using the wheel provided by Superdroid Robotics for now","title":"Components"},{"location":"Rover/hardware/#wiring-diagram","text":"","title":"Wiring diagram"},{"location":"Rover/hardware/#the-tool-positioning","text":"A CNC is adapted for use in the rover. We replaced the spindle that is normally used to carve wooden pieces, with a rotating weeding hoe. We are using to larger, 1000 mm sized version of the X-Carve . The newer X-Carve uses a custom design board for the control. However, we prefer using the older solution that combines an Arduino Uno with a gShield because it is smaller and more generic. For the time being, we use the grbl language to send commands from the embedded PC to the CNC controller. Therefore, any solution that accepts grbl commands should be drop-in solution for the Uno+gShield combo. Component Specifications Example CNC Minimum work area: 0.7 m x 0.7m X-Carve Optional: Controller board Must run grbl interpreter Arduino Uno Optional: Stepper drivers (3 steppers) The driver must use the STEP/DIR control signals gShield [Arduino CNC Shield] eBay and RepRap You can still have a look at XCarve's older documentation on how to wire the controller boards: http://x-carve-instructions.inventables.com/xcarve2015/step10/ http://x-carve-instructions.inventables.com/xcarve2015/step14/ Notable, the following two diagrams are of interest: The yellow wire marked \"spinle\" in the image above is used to turn the weeding hoe on or off, as shown in the figure below (see also the figure in the section on the power circuit).","title":"The tool positioning"},{"location":"Rover/manual/","text":"TODO: Overview Preparing the beds Main components of the rover Charging the battery Turning the rover on/off The web interface Configuration Calibration Starting a program Modifying a program Adding a program Assistance Troubleshooting","title":"User Manual"},{"location":"Rover/software/","text":"Overview Link This document describes how to run and compile the software for the ROMI Rover. If you are a developer looking for details on the source code then have a look at the separate Developer Documentation . Prerequisites Link The software of the rover runs on Linux. It is not tied to a specific Linux distribution but we have tested it mostly on recent versions of Debian (includin Raspian) and Ubuntu. The software is mostly writen in C and depends on the following libraries: libr : Common code for the rcom and the libromi libraries. It provides some OS abstraction (for example for threads, memory allocation, file system, networking), some core functionality (logging, time), and some base classes (variable-size memory buffers, json parser, lists, serial connections). Code rcom : An inter-process communication framework. It provides real-time communication using UDP messages and high-level communication based on web protocols (HTTP, Websockets). It also includes several utilities to develop and manage rcom applications. Code libromi : Base classes for the romi rover: fsdb (database with filesystem back-end), image loading and manipulations, \u2026) Code romi-brush-motor-controller : The motor controller. Code romi-rover : All of the apps for the Romi rover. Code By default, the rover uses a USB camera. It is possible to use the Intel Realsense camera on the Picamera instead. In that case, you will have to install additional libraries (see XXX). Installing a Raspberry Pi from scratch Link We use the Lite version of Raspbian. You can download it at https://www.raspberrypi.org/downloads/raspbian/ . There are several ways to prepare the disk image for the RPi. Check the page at https://www.raspberrypi.org/documentation/installation/installing-images/ (there\u2019s lots of information available on this topic online) and follow the instructions that suit you best. Once you have the SD card, connect RPi to screen, keyboard and network (ethernet), power up the board and log in (user pi , password raspberry ). The first thing you want to do is change some of the default settings using the raspi-config tool. In the console type: $ sudo raspi-config The list of settings that you may want to look at includes: 1 Change User Password 2 Network Options Hostname WiFi 4 Localisation Options Change locales Change keyboard layout 5 Interfacing Options Enable Camera Enable SSH 8 Update Next, create the user \u2018romi\u2019: $ sudo adduser romi $ sudo adduser romi dialout $ sudo adduser romi video $ sudo adduser romi sudo After that, quit the current session and login again as user \u2018romi\u2019. The nano text editor is installed by default but if you prefer anoher editor, now is a good time to install it: $ sudo apt install emacs-nox ( ... or any editor you like : ) Install the developer tools: $ sudo apt install build-essential cmake git Install the software dependencies: $ sudo apt install libpng-dev libjpeg9-dev That's it. You should be ready. Quick install #!/bin/bash # Install the dependencies sudo apt install build-essential cmake git libpng-dev libjpeg9-dev # Download, compile and install the libraries apps for id in libr rcom libromi romi-rover ; do echo ---------------------------------------------- echo Compiling $id # Download or update the github repository if [ -d $id ] ; then cd $id git pull else git clone https://github.com/romi/ $id .git cd $id fi # Standard cmake build sequence mkdir -p build cd build cmake .. make sudo make install sudo ldconfig # Get ready for the next component cd ../.. done Installing the romi-rover apps Link You should first install the libr , rcom , and libromi libraries. Check out their the Github pages for the installation instruction and the API documentation. You should also flash the motor controller to the Arduino (instructions are available on Github ) too. Once that is done, the installation of the romi-rover apps is straight-forward. First, check out the code: $ git clone https://github.com/romi/romi-rover.git Then proceed to the compilation and installation: $ cd romi-rover $ mkdir build $ cd build $ cmake .. $ make $ sudo make install Compiling the picamera app Link Although not currently used by the ROMI Rover, we have an Rcom app to access the Picamera. To get it working, you will first have to install the raspicam library: $ git clone https://github.com/cedricve/raspicam.git $ cd raspicam/ $ mkdir build $ cd build/ $ cmake .. $ make $ sudo make install $ sudo ldconfig Once raspicam is installed, you must re-run cmake to enable the compilation of the picamera app: $ cd romi-rover/build/ $ rm CMakeCache.txt $ cmake .. -DWITH_PICAMERA = ON $ make $ sudo make install Compiling the realsense app Link The fonctionality of the Realsense camera app is not complete. You can use it to obtain RGB images and depth images (as BW PNG images). You will first have to install librealsense2 . When librealsense is installed, re-run cmake to enable the compilation of the realsense app: $ cd romi-rover/build/ $ rm CMakeCache.txt $ cmake .. -DWITH_REALSENSE = ON $ make $ sudo make install Configuration Link Configuring the romi-rover apps Link In the directory /home/romi, create the following directories and copy the default configuration and script files: $ cd /home/romi $ mkdir sessions $ mkdir config $ cp romi-rover /config/config-romi-rover.json config/ $ mkdir scripts $ cp romi-rover /script/config-default.json scripts/ html : romi-rover /interface/html , Starting the apps on boot Link Currently we are still using the old rc.local mechanism. The file /etc/rc.local is no longer included in more recent Ubuntu versions. If ls / etc / rc . local returns an error, you will have to create the file as follows: $ sudo nano /etc/rc.local Copy the following contents: #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will exit 0 on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. exit 0 Finally, make the script executable. $ sudo chmod +x /etc/rc.local To enable the apps on start-up, add the following line in /etc/rc.local, above the exit 0 line: /usr/local/bin/rclaunch /home/romi/config/config-romi-rover.json Configuring the image uploads Link Annex: the apps and their options Link fake_camera : { image : data/camera.jpg } ,","title":"Software Installation"},{"location":"Rover/software/#overview","text":"This document describes how to run and compile the software for the ROMI Rover. If you are a developer looking for details on the source code then have a look at the separate Developer Documentation .","title":"Overview"},{"location":"Rover/software/#prerequisites","text":"The software of the rover runs on Linux. It is not tied to a specific Linux distribution but we have tested it mostly on recent versions of Debian (includin Raspian) and Ubuntu. The software is mostly writen in C and depends on the following libraries: libr : Common code for the rcom and the libromi libraries. It provides some OS abstraction (for example for threads, memory allocation, file system, networking), some core functionality (logging, time), and some base classes (variable-size memory buffers, json parser, lists, serial connections). Code rcom : An inter-process communication framework. It provides real-time communication using UDP messages and high-level communication based on web protocols (HTTP, Websockets). It also includes several utilities to develop and manage rcom applications. Code libromi : Base classes for the romi rover: fsdb (database with filesystem back-end), image loading and manipulations, \u2026) Code romi-brush-motor-controller : The motor controller. Code romi-rover : All of the apps for the Romi rover. Code By default, the rover uses a USB camera. It is possible to use the Intel Realsense camera on the Picamera instead. In that case, you will have to install additional libraries (see XXX).","title":"Prerequisites"},{"location":"Rover/software/#installing-a-raspberry-pi-from-scratch","text":"We use the Lite version of Raspbian. You can download it at https://www.raspberrypi.org/downloads/raspbian/ . There are several ways to prepare the disk image for the RPi. Check the page at https://www.raspberrypi.org/documentation/installation/installing-images/ (there\u2019s lots of information available on this topic online) and follow the instructions that suit you best. Once you have the SD card, connect RPi to screen, keyboard and network (ethernet), power up the board and log in (user pi , password raspberry ). The first thing you want to do is change some of the default settings using the raspi-config tool. In the console type: $ sudo raspi-config The list of settings that you may want to look at includes: 1 Change User Password 2 Network Options Hostname WiFi 4 Localisation Options Change locales Change keyboard layout 5 Interfacing Options Enable Camera Enable SSH 8 Update Next, create the user \u2018romi\u2019: $ sudo adduser romi $ sudo adduser romi dialout $ sudo adduser romi video $ sudo adduser romi sudo After that, quit the current session and login again as user \u2018romi\u2019. The nano text editor is installed by default but if you prefer anoher editor, now is a good time to install it: $ sudo apt install emacs-nox ( ... or any editor you like : ) Install the developer tools: $ sudo apt install build-essential cmake git Install the software dependencies: $ sudo apt install libpng-dev libjpeg9-dev That's it. You should be ready. Quick install #!/bin/bash # Install the dependencies sudo apt install build-essential cmake git libpng-dev libjpeg9-dev # Download, compile and install the libraries apps for id in libr rcom libromi romi-rover ; do echo ---------------------------------------------- echo Compiling $id # Download or update the github repository if [ -d $id ] ; then cd $id git pull else git clone https://github.com/romi/ $id .git cd $id fi # Standard cmake build sequence mkdir -p build cd build cmake .. make sudo make install sudo ldconfig # Get ready for the next component cd ../.. done","title":"Installing a Raspberry Pi from scratch"},{"location":"Rover/software/#installing-the-romi-rover-apps","text":"You should first install the libr , rcom , and libromi libraries. Check out their the Github pages for the installation instruction and the API documentation. You should also flash the motor controller to the Arduino (instructions are available on Github ) too. Once that is done, the installation of the romi-rover apps is straight-forward. First, check out the code: $ git clone https://github.com/romi/romi-rover.git Then proceed to the compilation and installation: $ cd romi-rover $ mkdir build $ cd build $ cmake .. $ make $ sudo make install","title":"Installing the romi-rover apps"},{"location":"Rover/software/#compiling-the-picamera-app","text":"Although not currently used by the ROMI Rover, we have an Rcom app to access the Picamera. To get it working, you will first have to install the raspicam library: $ git clone https://github.com/cedricve/raspicam.git $ cd raspicam/ $ mkdir build $ cd build/ $ cmake .. $ make $ sudo make install $ sudo ldconfig Once raspicam is installed, you must re-run cmake to enable the compilation of the picamera app: $ cd romi-rover/build/ $ rm CMakeCache.txt $ cmake .. -DWITH_PICAMERA = ON $ make $ sudo make install","title":"Compiling the picamera app"},{"location":"Rover/software/#compiling-the-realsense-app","text":"The fonctionality of the Realsense camera app is not complete. You can use it to obtain RGB images and depth images (as BW PNG images). You will first have to install librealsense2 . When librealsense is installed, re-run cmake to enable the compilation of the realsense app: $ cd romi-rover/build/ $ rm CMakeCache.txt $ cmake .. -DWITH_REALSENSE = ON $ make $ sudo make install","title":"Compiling the realsense app"},{"location":"Rover/software/#configuration","text":"","title":"Configuration"},{"location":"Rover/software/#configuring-the-romi-rover-apps","text":"In the directory /home/romi, create the following directories and copy the default configuration and script files: $ cd /home/romi $ mkdir sessions $ mkdir config $ cp romi-rover /config/config-romi-rover.json config/ $ mkdir scripts $ cp romi-rover /script/config-default.json scripts/ html : romi-rover /interface/html ,","title":"Configuring the romi-rover apps"},{"location":"Rover/software/#starting-the-apps-on-boot","text":"Currently we are still using the old rc.local mechanism. The file /etc/rc.local is no longer included in more recent Ubuntu versions. If ls / etc / rc . local returns an error, you will have to create the file as follows: $ sudo nano /etc/rc.local Copy the following contents: #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will exit 0 on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. exit 0 Finally, make the script executable. $ sudo chmod +x /etc/rc.local To enable the apps on start-up, add the following line in /etc/rc.local, above the exit 0 line: /usr/local/bin/rclaunch /home/romi/config/config-romi-rover.json","title":"Starting the apps on boot"},{"location":"Rover/software/#configuring-the-image-uploads","text":"","title":"Configuring the image uploads"},{"location":"Rover/software/#annex-the-apps-and-their-options","text":"fake_camera : { image : data/camera.jpg } ,","title":"Annex: the apps and their options"},{"location":"Scanner/","text":"Plant scanner overview Link Hereafter we illustrate the different components of the plant scanner and their interactions. User story: The user put his/her plant inside the scanner and run acquisitions , which returns a set of images per plant. These images are uploaded to a central database . The user defines a pipeline to reconstruct and quantify plants architecture by choosing among a set of predefined methods and algorithms. These instructions may be run by a distant server. Finally the user can access the acquisitions, reconstructions quantitative data by connecting to a visualization server using his/her computer","title":"Index"},{"location":"Scanner/#plant-scanner-overview","text":"Hereafter we illustrate the different components of the plant scanner and their interactions. User story: The user put his/her plant inside the scanner and run acquisitions , which returns a set of images per plant. These images are uploaded to a central database . The user defines a pipeline to reconstruct and quantify plants architecture by choosing among a set of predefined methods and algorithms. These instructions may be run by a distant server. Finally the user can access the acquisitions, reconstructions quantitative data by connecting to a visualization server using his/her computer","title":"Plant scanner overview"},{"location":"Scanner/conda/","text":"Conda Link Recipes to build conda packages can be found here . Follow theses instruction to build conda packages. Warning Conda packages should be built from the base environment. conda activate base Requirements Link Install conda - build : Link Install conda - build , in the base environment, to be able to build conda package: conda install conda-build WARNING: For macOS, follow these instructions to install the required macOS 10 . 9 SDK . Optional - Install anaconda - client : Link To be able to upload your package on anaconda cloud you need to install anaconda - client : conda install anaconda-client Build conda packages: Link Build lettucethink : Link Using the given recipe, it is easy to build the lettucethink - python conda package: cd conda_recipes/ conda build lettucethink/ --user romi-eu Build romidata : Link Using the given recipe, it is easy to build the romidata conda package: cd conda_recipes/ conda build romidata/ -c romi-eu -c open3d-admin --user romi-eu Build romiscan : Link Using the given recipe, it is easy to build the romiscan conda package: cd conda_recipes/ conda build romiscan/ -c romi-eu -c conda-forge -c open3d-admin --user romi-eu Build romi - plantviz : Link Using the given recipe, it is easy to build the romi - plantviz conda package: cd conda_recipes/ conda build romi-plantviz/ -c romi-eu -c conda-forge --user romi-eu Optional - Build dirsync package: Link To build dirsync you have to install hgsvn : sudo apt install hgsvn Using the given recipe, it is easy to build the dirsync conda package: cd conda_recipes conda build dirsync/recipe/ --user romi-eu Optional - Build opencv - python package: Link To build opencv - python you have to install qt4 - qmake : sudo apt install qt4-qmake qt4-default Using the given recipe, it is easy to build the opencv - python conda package: cd conda_recipes conda build opencv-python/ -c conda-forge --user romi-eu Conda useful commands: Link Purge built packages: Link conda build purge Clean cache unused packages: Link conda clean --all","title":"Conda"},{"location":"Scanner/conda/#conda","text":"Recipes to build conda packages can be found here . Follow theses instruction to build conda packages. Warning Conda packages should be built from the base environment. conda activate base","title":"Conda"},{"location":"Scanner/conda/#requirements","text":"","title":"Requirements"},{"location":"Scanner/conda/#install-conda-build","text":"Install conda - build , in the base environment, to be able to build conda package: conda install conda-build WARNING: For macOS, follow these instructions to install the required macOS 10 . 9 SDK .","title":"Install conda-build:"},{"location":"Scanner/conda/#optional-install-anaconda-client","text":"To be able to upload your package on anaconda cloud you need to install anaconda - client : conda install anaconda-client","title":"Optional - Install anaconda-client:"},{"location":"Scanner/conda/#build-conda-packages","text":"","title":"Build conda packages:"},{"location":"Scanner/conda/#build-lettucethink","text":"Using the given recipe, it is easy to build the lettucethink - python conda package: cd conda_recipes/ conda build lettucethink/ --user romi-eu","title":"Build lettucethink:"},{"location":"Scanner/conda/#build-romidata","text":"Using the given recipe, it is easy to build the romidata conda package: cd conda_recipes/ conda build romidata/ -c romi-eu -c open3d-admin --user romi-eu","title":"Build romidata:"},{"location":"Scanner/conda/#build-romiscan","text":"Using the given recipe, it is easy to build the romiscan conda package: cd conda_recipes/ conda build romiscan/ -c romi-eu -c conda-forge -c open3d-admin --user romi-eu","title":"Build romiscan:"},{"location":"Scanner/conda/#build-romi-plantviz","text":"Using the given recipe, it is easy to build the romi - plantviz conda package: cd conda_recipes/ conda build romi-plantviz/ -c romi-eu -c conda-forge --user romi-eu","title":"Build romi-plantviz:"},{"location":"Scanner/conda/#optional-build-dirsync-package","text":"To build dirsync you have to install hgsvn : sudo apt install hgsvn Using the given recipe, it is easy to build the dirsync conda package: cd conda_recipes conda build dirsync/recipe/ --user romi-eu","title":"Optional - Build dirsync package:"},{"location":"Scanner/conda/#optional-build-opencv-python-package","text":"To build opencv - python you have to install qt4 - qmake : sudo apt install qt4-qmake qt4-default Using the given recipe, it is easy to build the opencv - python conda package: cd conda_recipes conda build opencv-python/ -c conda-forge --user romi-eu","title":"Optional - Build opencv-python package:"},{"location":"Scanner/conda/#conda-useful-commands","text":"","title":"Conda useful commands:"},{"location":"Scanner/conda/#purge-built-packages","text":"conda build purge","title":"Purge built packages:"},{"location":"Scanner/conda/#clean-cache-unused-packages","text":"conda clean --all","title":"Clean cache &amp; unused packages:"},{"location":"Scanner/data/","text":"Data storage Link Getting started Link Installation Link Install from github using pip: romidata: pip install git + ssh : // git @github . com / romi / data - storage . git#dev Basic working example Link Assume you have a list of images you want to create a database, and add some images to a scan in this database. First create the folder for the database and add the romidb marker to it: mkdir mydb touch mydb / romidb Then in you python code: from romidata.fsdb import FSDB from romidata import io import numpy as np # Generate random noise images n_images = 100 imgs = [] for i in range ( n_images ): img = 256 * np . random . rand ( 256 , 256 , 3 ) img = np . array ( img , dtype = np . uint8 ) imgs . append ( img ) db = FSDB ( mydb ) db . connect () # Locks the database and allows access scan = db . create_scan ( myscan ) fileset = scan . create_fileset ( images ) for i , img in enumerate ( imgs ): file = fileset . create_file ( %i % i ) io . write_image ( file , img ) file . set_metadata ( key , %i % i ) # Add some metadata # read files in the fileset: scan = db . get_scan ( myscan ) fileset = scan . get_fileset ( images ) for f in fileset . get_files (): im = io . read_image ( f ) # reads image data print ( f . get_metadata ( key )) # i db . disconnect ()","title":"Data"},{"location":"Scanner/data/#data-storage","text":"","title":"Data storage"},{"location":"Scanner/data/#getting-started","text":"","title":"Getting started"},{"location":"Scanner/data/#installation","text":"Install from github using pip: romidata: pip install git + ssh : // git @github . com / romi / data - storage . git#dev","title":"Installation"},{"location":"Scanner/data/#basic-working-example","text":"Assume you have a list of images you want to create a database, and add some images to a scan in this database. First create the folder for the database and add the romidb marker to it: mkdir mydb touch mydb / romidb Then in you python code: from romidata.fsdb import FSDB from romidata import io import numpy as np # Generate random noise images n_images = 100 imgs = [] for i in range ( n_images ): img = 256 * np . random . rand ( 256 , 256 , 3 ) img = np . array ( img , dtype = np . uint8 ) imgs . append ( img ) db = FSDB ( mydb ) db . connect () # Locks the database and allows access scan = db . create_scan ( myscan ) fileset = scan . create_fileset ( images ) for i , img in enumerate ( imgs ): file = fileset . create_file ( %i % i ) io . write_image ( file , img ) file . set_metadata ( key , %i % i ) # Add some metadata # read files in the fileset: scan = db . get_scan ( myscan ) fileset = scan . get_fileset ( images ) for f in fileset . get_files (): im = io . read_image ( f ) # reads image data print ( f . get_metadata ( key )) # i db . disconnect ()","title":"Basic working example"},{"location":"Scanner/docker/","text":"Docker containers for ROMI Link List of docker containers Link We hereafter list the docker containers, their use and list the installed libraries: romiDB: the database container, gather the acquired images, reconstructed plants architectures quantitative data - libraries: [ romidata , ...? ]; romiScanner: the scanner container, pilot the hardware components - libraries: [ lettucethink - python , ...? ]; romiSmartInterpreter: the reconstruction and quantification container, gather the algorithms and processing pipelines to extract quantitative biological information on plants architecure from a set of photo acquisition - libraries: [ romiscan , ...? ]; romiVirtualScanner: the virtual scanner container, gather the tools to create virtual plants and render realistic snapshots - libraries: [ ? , ...? ]; visualizer: the plant visualizer, webapp that dialog with the database to display images some quantitative traits - libraries: [ sony_visualiseur - plantes - 3 d , romidata , ...? ]; romiDB Link continuumio/miniconda3 romiScanner Link continuumio/miniconda3 romiSmartInterpreter Link FROM colmap/colmap romiVirtualScanner Link FROM visualizer Link FROM alpine:3.10 scanner - rest - api npm start are two distinct process to start ! DockerHub: colmap Link Docker images for the COLMAP open source project: https://hub.docker.com/r/colmap/colmap nvidia/cuda with colmap - (compatible with Driver Version: 418.67 CUDA Version: 10.1) https://hub.docker.com/r/geki/colmap","title":"Docker"},{"location":"Scanner/docker/#docker-containers-for-romi","text":"","title":"Docker containers for ROMI"},{"location":"Scanner/docker/#list-of-docker-containers","text":"We hereafter list the docker containers, their use and list the installed libraries: romiDB: the database container, gather the acquired images, reconstructed plants architectures quantitative data - libraries: [ romidata , ...? ]; romiScanner: the scanner container, pilot the hardware components - libraries: [ lettucethink - python , ...? ]; romiSmartInterpreter: the reconstruction and quantification container, gather the algorithms and processing pipelines to extract quantitative biological information on plants architecure from a set of photo acquisition - libraries: [ romiscan , ...? ]; romiVirtualScanner: the virtual scanner container, gather the tools to create virtual plants and render realistic snapshots - libraries: [ ? , ...? ]; visualizer: the plant visualizer, webapp that dialog with the database to display images some quantitative traits - libraries: [ sony_visualiseur - plantes - 3 d , romidata , ...? ];","title":"List of docker containers"},{"location":"Scanner/docker/#romidb","text":"continuumio/miniconda3","title":"romiDB"},{"location":"Scanner/docker/#romiscanner","text":"continuumio/miniconda3","title":"romiScanner"},{"location":"Scanner/docker/#romismartinterpreter","text":"FROM colmap/colmap","title":"romiSmartInterpreter"},{"location":"Scanner/docker/#romivirtualscanner","text":"FROM","title":"romiVirtualScanner"},{"location":"Scanner/docker/#visualizer","text":"FROM alpine:3.10 scanner - rest - api npm start are two distinct process to start !","title":"visualizer"},{"location":"Scanner/docker/#dockerhub-colmap","text":"Docker images for the COLMAP open source project: https://hub.docker.com/r/colmap/colmap nvidia/cuda with colmap - (compatible with Driver Version: 418.67 CUDA Version: 10.1) https://hub.docker.com/r/geki/colmap","title":"DockerHub: colmap"},{"location":"Scanner/hardware/","text":"Hardware setup and instructions Link Hardware configuration files Link To gather configuration information of the hardware we use toml files to define variables. This allows for easy import in python. For example, saving the following lines in a config . toml : [Scan.scanner] camera_firmware = sony_wifi cnc_firmware = grbl-v1.1 gimbal_firmware = blgimbal In python: import toml conf = toml . load ( open ( config.toml )) print ( conf ) { Scan : { scanner : { camera_firmware : sony_wifi , cnc_firmware : grbl-v1.1 , gimbal_firmware : blgimbal }}} print ( conf [ Scan ][ scanner ][ camera_firmware ]) sony_wifi PiZero camera rovercam Link WORK IN PROGRESS!!!!! Configuring the access point host software (hostapd) Link Source: Raspberry Foundation website . 1. General setup Link Switch over to systemd - networkd : # deinstall classic networking sudo apt --autoremove purge ifupdown dhcpcd5 isc-dhcp-client isc-dhcp-common rm -r /etc/network /etc/dhcp # enable systemd-networkd systemctl enable systemd-networkd.service # setup systemd-resolved systemctl enable systemd-resolved.service apt --autoremove purge avahi-daemon apt install libnss-resolve ln -sf /run/systemd/resolve/stub-resolv.conf /etc/resolv.conf 2. Configure wpa_supplicant as access point Link To configure wpa_supplicant as access point create this file with your settings for country = , ssid = , psk = and maybe frequency = . You can just copy and paste this in one block to your command line beginning with cat and including both EOF (delimiter EOF will not get part of the file): cat / etc / wpa_supplicant / wpa_supplicant - wlan0 . conf EOF country = DE ctrl_interface = DIR =/ var / run / wpa_supplicant GROUP = netdev update_config = 1 network = { ssid = RPiNet mode = 2 frequency = 2437 # key_mgmt = NONE # uncomment this for an open hotspot # delete next 3 lines if key_mgmt = NONE key_mgmt = WPA - PSK proto = RSN WPA psk = password } EOF chmod 600 /etc/wpa_supplicant/wpa_supplicant-wlan0.conf systemctl disable wpa_supplicant.service systemctl enable wpa_supplicant@wlan0.service Setting up a stand alone access point Link Example for this setup: wifi mobile-phone ~.~.~.~.~ ( wlan0 ) RPi ( eth0 ) \\ / ( dhcp ) 192 .168.4.1 Do \"General setup\" then create the following file to configure wlan0 . We only have the access point. There is no ethernet device configured. cat /etc/systemd/network/08-wlan0.network EOF [Match] Name=wlan0 [Network] Address=192.168.4.1/24 MulticastDNS=yes DHCPServer=yes EOF If you want this then reboot. That's it. Otherwise go on, no need to reboot at this time.","title":"Hardware"},{"location":"Scanner/hardware/#hardware-setup-and-instructions","text":"","title":"Hardware setup and instructions"},{"location":"Scanner/hardware/#hardware-configuration-files","text":"To gather configuration information of the hardware we use toml files to define variables. This allows for easy import in python. For example, saving the following lines in a config . toml : [Scan.scanner] camera_firmware = sony_wifi cnc_firmware = grbl-v1.1 gimbal_firmware = blgimbal In python: import toml conf = toml . load ( open ( config.toml )) print ( conf ) { Scan : { scanner : { camera_firmware : sony_wifi , cnc_firmware : grbl-v1.1 , gimbal_firmware : blgimbal }}} print ( conf [ Scan ][ scanner ][ camera_firmware ]) sony_wifi","title":"Hardware configuration files"},{"location":"Scanner/hardware/#pizero-camera-rovercam","text":"WORK IN PROGRESS!!!!!","title":"PiZero camera rovercam"},{"location":"Scanner/hardware/#configuring-the-access-point-host-software-hostapd","text":"Source: Raspberry Foundation website .","title":"Configuring the access point host software (hostapd)"},{"location":"Scanner/hardware/#1-general-setup","text":"Switch over to systemd - networkd : # deinstall classic networking sudo apt --autoremove purge ifupdown dhcpcd5 isc-dhcp-client isc-dhcp-common rm -r /etc/network /etc/dhcp # enable systemd-networkd systemctl enable systemd-networkd.service # setup systemd-resolved systemctl enable systemd-resolved.service apt --autoremove purge avahi-daemon apt install libnss-resolve ln -sf /run/systemd/resolve/stub-resolv.conf /etc/resolv.conf","title":"1. General setup"},{"location":"Scanner/hardware/#2-configure-wpa_supplicant-as-access-point","text":"To configure wpa_supplicant as access point create this file with your settings for country = , ssid = , psk = and maybe frequency = . You can just copy and paste this in one block to your command line beginning with cat and including both EOF (delimiter EOF will not get part of the file): cat / etc / wpa_supplicant / wpa_supplicant - wlan0 . conf EOF country = DE ctrl_interface = DIR =/ var / run / wpa_supplicant GROUP = netdev update_config = 1 network = { ssid = RPiNet mode = 2 frequency = 2437 # key_mgmt = NONE # uncomment this for an open hotspot # delete next 3 lines if key_mgmt = NONE key_mgmt = WPA - PSK proto = RSN WPA psk = password } EOF chmod 600 /etc/wpa_supplicant/wpa_supplicant-wlan0.conf systemctl disable wpa_supplicant.service systemctl enable wpa_supplicant@wlan0.service","title":"2. Configure wpa_supplicant as access point"},{"location":"Scanner/hardware/#setting-up-a-stand-alone-access-point","text":"Example for this setup: wifi mobile-phone ~.~.~.~.~ ( wlan0 ) RPi ( eth0 ) \\ / ( dhcp ) 192 .168.4.1 Do \"General setup\" then create the following file to configure wlan0 . We only have the access point. There is no ethernet device configured. cat /etc/systemd/network/08-wlan0.network EOF [Match] Name=wlan0 [Network] Address=192.168.4.1/24 MulticastDNS=yes DHCPServer=yes EOF If you want this then reboot. That's it. Otherwise go on, no need to reboot at this time.","title":"Setting up a stand alone access point"},{"location":"Scanner/how-to/","text":"Scanner Link This is a document centralizing all documentation for the 3D scanner. The 3D scanner software is composed of several python libraries organized in different packages: romidata : the data processing module lettucethink : the hardware interface romiscan : the computer vision algorithms romiseg : the segmentation models Additionally, some CGAL bindings are implemented in a separate python library: cgal_bindings_skeletonization . A separate repository is dedicated to the virtual scanner, which is available as a blender python (bpy) script. Getting started Link Installation Link There are some requirements to use the different algorithms in the pipeline. Most of them are installed automatically from the requirements file when using pip. The most important part is Colmap (v3.6). Preferably, create a virtual environment for python 3.7 or python 3.8 using virtualenv or a conda environment specific to the 3D Scanner. Beware : if using python 3.8, Open3D binaries are not yet available on pip, therefore you have to build Open3D from sources! A - Create a virtual environment Link virtualenv -p /usr/bin/python3.7 scan3d source scan3d/bin/activate B - Create a conda environment: Link conda create -n scan3d Install colmap : Link Follow the procedure from the official documentation here . Make sure to use version 3.6. TODO: use COLMAP python build script to make conda package? Note: If you are using a conda environment, you can install ceres - solver dependency for COLMAP from the conda-forge channel: conda install ceres-solver -c conda-forge Optional - Use NVIDIA for OpenCL Link If you want to use NVIDIA for OpenCL in the processing pipeline, install pyopencl from source, and configure it to use OpenCL 1.2 (NVIDIA does not support the default OpenCL 2.0). First, make sure you have python headers installed, on ubuntu: apt install python3.7-dev Then install pyopencl from source, and configure it to use OpenCL 1.2: git clone https://github.com/inducer/pyopencl cd pyopencl git submodule update --init pip install pybind11 mako ./configure.py --cl-pretend-version = 1 .2 # NVIDIA has bad OpenCL support and only provides OpenCL 1.2 python setup.py install cd .. Install romidata , lettucethink cgal_bindings_skeletonization with pip : Link To install directly using pip , you need ssh access to the ROMI repository on GitHub! Install romidata : Link pip install git+https://github.com/romi/data-storage.git@dev Install lettucethink : Link pip install git+https://github.com/romi/lettucethink-python@dev Install cgal_bindings_skeletonization : Link pip install git+https://github.com/romi/cgal_bindings_skeletonization Note: this takes some time since it has to download dependencies and compile Install Scan3D : Link A - From sources: Link Clone the Scan3D repository and install requirements git clone https://github.com/romi/Scan3D cd Scan3D git checkout dev pip install . B - From pip : Link pip install git+https://github.com/romi/Scan3D@dev The Scan3D package is now installed. Optional - Install romiseg : Link To install the additional segmentation module: pip install git+ssh://git@github.com/romi/Segmentation@dev (TODO: make romiseg public) Beware: If not using CUDA 10.0, you have to install the matching pytorch distribution: for example, for CUDA 9.2, use pip install torch == 1 . 4 . 0 + cu92 - f https : // download . pytorch . org / whl / torch_stable . html Initializing a Database Link The FSDB class from the romidata module is used for data storage. A database is any folder which contains a file named romidb . To create an empty database, just create a new folder and an empty file named romidb in it. Processing pipelines Link Testing on a test db Link Get the test DB from : wget https://db.romi-project.eu/models/test_db.tar.gz Extract it: tar -xvf test_db.tar.gz Test the virtual plant pipeline on a virtual scan: run-task --config Scan3D/default/segmentation2d_arabidopsis.toml PointCloud integration_tests/arabidopsis_26 --log-level DEBUG --local-scheduler This should process all dependencies to obtain a segmented \"PointCloud.ply\" ! Basic usage Link Every task on the scanner is launched through the run - task command provided in the romiscan module. It is a wrapper for luigi , with preloaded tasks from the romiscan module. The general usage is as follows: run-task [ -h ] [ --config CONFIG ] [ --luigicmd LUIGICMD ] [ --module MODULE ] [ --local-scheduler ] [ --log-level LOG_LEVEL ] task scan CONFIG is either a file or a folder. If a file, it must be json or toml and contains the configuration of the task to run. If a folder, it will read all configuration files in json or toml format from the folder. LUIGICMD is an optional parameter specifying an alternative command for luigi . MODULE is an optional parameter for running task from external modules (see TODO). LOG_LEVEL is the level of logging. Defaults to INFO , but can be set to DEBUG to increase verbosity. task is the name of the class to run (see TODO) scan is the location of the target scan on which to process the task. It is of the form DB_LOCATION / SCAN_ID , where DB_LOCATION is a path containing the romidb marker. Configuration files Link The configuration is in the form of a dictionary, in which each key is the ID of a given task. In toml format, it reads as follows: [FirstTask] parameter1 = value1 parameter2 = value2 [SecondTask] parameter1 = value1 parameter2 = value2 Running scans Link Scan is the basic task for running a task with the scanner. A sample configuration file for the (real) scanner is as follows: To see available parameters for scanner, camera, CNC, check the lettucethink module. Create a file named scanner . toml with the following text, adjusting parameters as needed for the actual configuration of the scanner. Check the lettucethink documentation for additional information. [Scan.scanner] camera_firmware = sony_wifi cnc_firmware = grbl-v1.1 gimbal_firmware = blgimbal [ Scan . scanner . scanner_args ] # These are the kwargs passed to the scanner constructor inverted = false [ Scan . scanner . camera_args ] # These are the kwargs passed to the camera constructor postview = true device_ip = 10.0.2.66 api_port = 10000 [ Scan . scanner . cnc_args ] # These are kwargs passed to the CNC constructor homing = true port = /dev/ttyUSB0 [Scan.scanner.gimbal_args] port = /dev/ttyACM1 has_tilt = false zero_pan = 145 [ Scan . scanner . camera_model ] # This is a precalibrated camera model width = 1616 height = 1080 id = 1 model = OPENCV params = [ 1120.72122223961, 1120.72122223961, 808.0, 540.0, 0.0007513494532588769, 0.0007513494532588769, 0.0, 0.0,] [ Scan . scanner . workspace ] # A volume containing the target scanned object x = [ 200, 600,] y = [ 200, 600,] z = [ -100, 300,] [ Scan . path ] # Example circular scan with 72 points: type = circular [Scan.path.args] num_points = 3 radius = 350 tilt = 0.45 # rad xc = 400 yc = 400 z = 0 [Scan.metadata] key = value # Any metadata you want to add to the scan Then, run a scan using run-task --config scanner.json Scan /path/to/db/scan_id/ --local-scheduler / path / to / db must be an existing FSDB database and scan_id must not already exist in the database. This will create the corresponding folder and fill it with images from the scan. Pipelines Link This is a sample configuration for the full pipeline: [Colmap] matcher = exhaustive compute_dense = false [Colmap.cli_args.feature_extractor] --ImageReader.single_camera = 1 --SiftExtraction.use_gpu = 1 [Colmap.cli_args.exhaustive_matcher] --SiftMatching.use_gpu = 1 [Colmap.cli_args.model_aligner] --robust_alignment_max_error = 10 [Masks] type = excess_green dilation = 5 binarize = true threshold = 0.0 [Voxels] voxel_size = 1.0 type = carving [PointCloud] level_set_value = 1.0 [Visualization] max_image_size = 1500 max_pcd_size = 10000 thumbnail_size = 150 pcd_source = vox2pcd mesh_source = delaunay To run the pipeline use run - task run-task --config scanner.json AnglesAndInternodes /path/to/db/scan_id/ --local-scheduler This will process all tasks up to the AnglesAndInternodes task. Every task produces a Fileset , a subdirectory in the scan directory whose name starts the same as the task name. The characters following are a hash of the configuration of the task, so that the outputs of the same task with different parameters can coexist in the same scan. Any change in the parameters will make the needed task to be recomputed with subsequent calls of run - task . Already computed tasks will be left untouched. To recompute a task, just delete the corresponding folder in the scan directory and rerun run - task . Default task reference Link default_modules = { \"Scan\": \"romiscan.tasks.scan\", \"Clean\": \"romiscan.tasks.scan\", \"CalibrationScan\": \"romiscan.tasks.scan\", \"Colmap\": \"romiscan.tasks.colmap\", \"Undistorted\": \"romiscan.tasks.proc2d\", \"Masks\": \"romiscan.tasks.proc2d\", \"Segmentation2D\": \"romiscan.tasks.proc2d\", \"Voxels\": \"romiscan.tasks.cl\", \"PointCloud\": \"romiscan.tasks.proc3d\", \"TriangleMesh\": \"romiscan.tasks.proc3d\", \"CurveSkeleton\": \"romiscan.tasks.proc3d\", \"TreeGraph\": \"romiscan.tasks.arabidopsis\", \"AnglesAndInternodes\": \"romiscan.tasks.arabidopsis\", \"Visualization\": \"romiscan.tasks.visualization\" } Class name : Scan Module : romiscan . tasks . scan Description : A task for running a scan , real or virtual . Default upstream tasks : None Parameters : - metadata ( DictParameter ) : metadata for the scan - scanner ( DictParameter ) : scanner hardware configuration ( TODO : see hardware documentation ) - path ( DictParameter ) : scanner path configuration ( TODO : see hardware documentation ) Class name : CalibrationScan Module : romiscan . tasks . scan Description : A task for running a scan , real or virtual , with a calibration path . It is used to calibrate Colmap poses for subsequent scans . ( TODO : see calibration documentation ) Default upstream tasks : None Parameters : - metadata ( DictParameter ) : metadata for the scan - scanner ( DictParameter ) : scanner hardware configuration ( TODO : see hardware documentation ) - path ( DictParameter ) : scanner path configuration ( TODO : see hardware documentation ) - n_line : number of shots taken on the orthogonal calibration lines Class name : Clean Module : romiscan . tasks . scan Description : Cleanup a scan , keeping only the images fileset and removing all computed pipelines . Default upstream tasks : None Parameters : - no_confirm ( BoolParameter , default = False ) : do not ask for confirmation in the command prompt . Class name : Colmap Module : romiscan . tasks . colmap Description : Runs colmap on a given scan . Default upstream tasks : Scan Upstream task format : Fileset with image files Output fileset format : images . json , cameras . json , points3D . json , sparse . ply [, dense . ply ] Parameters : - matcher ( Parameter , default = exhaustive ) : either exhaustive or sequential ( TODO : see colmap documentation ) - compute_dense ( BoolParameter ) : whether to run the dense colmap to obtain a dense point cloud - cli_args ( DictParameter ) : parameters for colmap command line prompts ( TODO : see colmap documentation ) - align_pcd ( BoolParameter , default = True ) : align point cloud on calibrated or metadata poses ? - calibration_scan_id ( Parameter , default = ) : ID of the calibration scan . Class name : Undistorted Module : romiscan . tasks . proc2d Description : Undistorts images using computed intrinsic camera parameters Default upstream tasks : Scan , Colmap Upstream task format : Fileset with image files Output fileset format : Fileset with image files Class name : Masks Module : romiscan . tasks . proc2d Description : compute masks using several functions Default upstream tasks : Undistorted Upstream task format : Fileset with image files Output fileset format : Fileset with grayscale or binary image files Parameters : - type ( Parameter ) : linear , excess_green , vesselness , invert ( TODO : see segmentation documentation ) - parameters ( ListParameter ) : list of scalar parmeters , depends on type - dilation ( IntParameter ) : by how much to dilate masks if binary - binarize ( BoolParameter , default = True ) : binarize the masks - threshold ( FloatParameter , default = 0 . 0 ) : threshold for binarization - Class name : Segmentation2D Module : romiscan . tasks . proc2d Description : compute masks using trained deep learning models Default upstream tasks : Undistorted Upstream task format : Fileset with image files Output fileset format : Fileset with grayscale image files , each corresponding to a given input image and class Parameters : - query ( DictParameter ) : query to pass to upstream fileset . It filters file by metadata , e . g { channel : rgb } will process only input files such that channel metadata is equal to rgb . - labels ( Parameter ) : string of the form a,b,c such that a , b , c are the identifiers of the labels produced by the neural network - Sx , Sy ( IntParametr ) : size of the input of the neural network . Input pictures are cropped in the center to this size . - model_segmentation_name : name of .pt file that can be found at ` https : // db . romi - project . eu / models ` - Class name : Voxels Module : romiscan . tasks . cl Description : Computes a volume from backprojection of 2 D segmented images Default upstream tasks : - upstream_mask : Masks - upstream_colmap : Colmap Upstream task format : - upstream_mask : Fileset with grayscale images - upstream_colmap : Output of Colmap task Output fileset format : npz file with as many arrays as classes Parameters : - use_colmap_poses ( BoolParameter , default = True ) : Either use precomputed camera poses or output from the Colmap task - voxel_size ( FloatParameter ) : size of one side of voxels - type ( Parameter ) : carving or averaging ( TODO : See 3 D documentation ) - multiclass ( BoolParameter , default = False ) : whether input data is single class or multiclass ( e . g as an output of Segmentation2D ) - log ( BoolParameter , default = True ) , in the case of averaging type , whether to apply log when averaging values . Class name : PointCloud Module : romiscan . tasks . proc3d Description : Computes a point cloud from volumetric voxel data ( either single or multiclass ) Default upstream tasks : Voxels Upstream task format : npz file with as many 3 D array as classes Output task format : single point cloud in ply . Metadata may include label name if multiclass . Class name : TriangleMesh Module : romiscan . tasks . proc3d Description : Triangulates input point cloud . Currently ignores class data and needs only one connected component . Default upstream tasks : PointCloud Upstream task format : ply file Output task format : ply triangle mesh file Class name : CurveSkeleton Module : romiscan . tasks . proc3d Description : Creates a 3 D curve skeleton Default upstream tasks : TriangleMesh Upstream task format : ply triangle mesh Output task format : json with two entries points and lines ( TODO : precise ) Class name : TreeGraph Module : romiscan . tasks . arabidopsis Description : Creates a tree graph of the plant Default upstream tasks : CurveSkeleton Upstream task format : json Output task format : json ( TODO : precise ) Class name ; AnglesAndInternodes Module : romiscan . tasks . arabidopsis Description : Computes angles and internode Default upstream tasks : TreeGraph Upstream task format : json Output task format : json ( TODO : precise ) Visualizer Link Running a development server for the visualizer Link Clone the visualizer git repository : git clone git@github.com:romi/sony_visualiseur-plantes-3d.git cd sony_visualiseur-plantes-3d Install node packages and build the pages: npm install Set the DB location using the DB_LOCATION environment variable: export DB_LOCATION = /path/to/the/db Launch the flask development server: scanner-rest-api Finally, start the frontend development server: npm start You can now access the visualizer on http://localhost:3000 . Ready to run docker image Link See: visualizer docker image. Visualizer API reference Link Virtual scanner Link Basic usage Link The virtual scanner works like an HTTP server using Blender. First, make sure you have blender ( = 2.80) installed on your machine. Then, clone the directory and access it: git clone git@github.com:romi/blender_virtual_scanner.git cd blender_virtual_scanner You can obtain sample data for the scanner here, and put it in the data folder. wget https://db.romi-project.eu/models/arabidopsis_data.zip unzip arabidopsis_data.zip -d data To use custom data, it must consist in .obj file, in which each type of organ corresponds to a distinct mesh. This mesh must have a single material whose name is the name of the organ. The data dir must contain the obj and mtl files. Additionally, background HDRI files can be downloaded from (hdri haven)[ https://hdrihaven.com/ ]. Download .hdr files and put them in the hdri folder. To start the virtual scanner, run the following script in blender: blender [ scene/texture.blend ] -b -P scan.py It will start an HTTP server on port 5000 . Preparing data Link If you have 3D models with a single mesh Running a scan (with romiscan and lettucethink ) Link The virtual scanner is integrated in lettucethink-python, so that it can be used directly with the Scan task in run - task . Here is a sample configuration for the virtual scanner creating 640x480 images with ground truth segmentation of organs. The server mentioned above must be running before running run - task . [Scan.scanner] camera_firmware = virtual cnc_firmware = virtual gimbal_firmware = virtual id = virtual [Scan.path] id = virtual type = circular [Scan.scanner.scanner_args] inverted = false [Scan.scanner.camera_args] width = 640 height = 480 focal = 25 render_ground_truth = true load_object = arabidopsis_0.obj?dx=10 dy=10 dz=-5 load_background = quarry_03_8k.hdr [Scan.scanner.cnc_args] [Scan.scanner.gimbal_args] [Scan.scanner.workspace] x = [ 200, 600,] y = [ 200, 600,] z = [ -100, 300,] [Scan.path.args] num_points = 10 radius = 100 tilt = 0.45 xc = 0 yc = 0 z = 50 Running the pipeline with ground-truth poses (without Colmap) Link To run the pipeline without colmap and use the virtual scanner poses as a ground truth, one must use set the following parameters: [Voxels] use_colmap_poses = false [Masks] upstream_task = Scan Then the pipeline can be run as usual and colmap will not be run. Scanner API reference Link Objects Link / objects (GET): retrieve the list of obj files in the data folder that can be loaded. / load_object / object_id (GET) load the given object in the scene. Takes a translation vector as URL parameters ( dx , dy , dz ) Classes Link / classes (GET): retrieve the list of classes. Backgrounds Link / backgrounds (GET): retrieve the list of hdr files in the hdri folder that can be loaded. / load_background / background_id (GET) load the given background in the scene. Camera Link / camera_intrinsics (POST): set camera intrinsics. Keys: width , height , focal / camera_pose (POST): set camera pose. Keys: tx , ty , tz , rx , ry , rz Rendering Link / render (GET): gets the rendering of the scene / render_class / class_id (GET) renders the scene, with everything transparent except the given class TODO: missing endpoints httpie # Setup camera http - f post http : // localhost : 5000 / camera_intrinsics width = 1920 height = 1080 focal = 35 # Load arabidopsis_0 http get http://localhost:5000/load_object/arabidopsis_0.obj?dx=10 dy=20 dz=1 # Load old tree in the park background http get http : // 127 . 0 . 0 . 1 : 5000 / load_background / old_tree_in_city_park_8k . hdr # Move camera http - f post http : // localhost : 5000 / camera_pose tx =- 60 ty = 0 tz = 50 rx = 60 ry = 0 rz =- 90 # Render scene and download image http --download get http://localhost:5000/render # Render only leaves http --download get http://localhost:5000/render_class/Color_7","title":"How to"},{"location":"Scanner/how-to/#scanner","text":"This is a document centralizing all documentation for the 3D scanner. The 3D scanner software is composed of several python libraries organized in different packages: romidata : the data processing module lettucethink : the hardware interface romiscan : the computer vision algorithms romiseg : the segmentation models Additionally, some CGAL bindings are implemented in a separate python library: cgal_bindings_skeletonization . A separate repository is dedicated to the virtual scanner, which is available as a blender python (bpy) script.","title":"Scanner"},{"location":"Scanner/how-to/#getting-started","text":"","title":"Getting started"},{"location":"Scanner/how-to/#installation","text":"There are some requirements to use the different algorithms in the pipeline. Most of them are installed automatically from the requirements file when using pip. The most important part is Colmap (v3.6). Preferably, create a virtual environment for python 3.7 or python 3.8 using virtualenv or a conda environment specific to the 3D Scanner. Beware : if using python 3.8, Open3D binaries are not yet available on pip, therefore you have to build Open3D from sources!","title":"Installation"},{"location":"Scanner/how-to/#a-create-a-virtual-environment","text":"virtualenv -p /usr/bin/python3.7 scan3d source scan3d/bin/activate","title":"A - Create a virtual environment"},{"location":"Scanner/how-to/#b-create-a-conda-environment","text":"conda create -n scan3d","title":"B - Create a conda environment:"},{"location":"Scanner/how-to/#install-colmap","text":"Follow the procedure from the official documentation here . Make sure to use version 3.6. TODO: use COLMAP python build script to make conda package? Note: If you are using a conda environment, you can install ceres - solver dependency for COLMAP from the conda-forge channel: conda install ceres-solver -c conda-forge","title":"Install colmap:"},{"location":"Scanner/how-to/#optional-use-nvidia-for-opencl","text":"If you want to use NVIDIA for OpenCL in the processing pipeline, install pyopencl from source, and configure it to use OpenCL 1.2 (NVIDIA does not support the default OpenCL 2.0). First, make sure you have python headers installed, on ubuntu: apt install python3.7-dev Then install pyopencl from source, and configure it to use OpenCL 1.2: git clone https://github.com/inducer/pyopencl cd pyopencl git submodule update --init pip install pybind11 mako ./configure.py --cl-pretend-version = 1 .2 # NVIDIA has bad OpenCL support and only provides OpenCL 1.2 python setup.py install cd ..","title":"Optional - Use NVIDIA for OpenCL"},{"location":"Scanner/how-to/#install-romidata-lettucethink-cgal_bindings_skeletonization-with-pip","text":"To install directly using pip , you need ssh access to the ROMI repository on GitHub!","title":"Install romidata, lettucethink &amp; cgal_bindings_skeletonization with pip:"},{"location":"Scanner/how-to/#install-romidata","text":"pip install git+https://github.com/romi/data-storage.git@dev","title":"Install romidata:"},{"location":"Scanner/how-to/#install-lettucethink","text":"pip install git+https://github.com/romi/lettucethink-python@dev","title":"Install lettucethink:"},{"location":"Scanner/how-to/#install-cgal_bindings_skeletonization","text":"pip install git+https://github.com/romi/cgal_bindings_skeletonization Note: this takes some time since it has to download dependencies and compile","title":"Install cgal_bindings_skeletonization:"},{"location":"Scanner/how-to/#install-scan3d","text":"","title":"Install Scan3D:"},{"location":"Scanner/how-to/#a-from-sources","text":"Clone the Scan3D repository and install requirements git clone https://github.com/romi/Scan3D cd Scan3D git checkout dev pip install .","title":"A - From sources:"},{"location":"Scanner/how-to/#b-from-pip","text":"pip install git+https://github.com/romi/Scan3D@dev The Scan3D package is now installed.","title":"B - From pip:"},{"location":"Scanner/how-to/#optional-install-romiseg","text":"To install the additional segmentation module: pip install git+ssh://git@github.com/romi/Segmentation@dev (TODO: make romiseg public) Beware: If not using CUDA 10.0, you have to install the matching pytorch distribution: for example, for CUDA 9.2, use pip install torch == 1 . 4 . 0 + cu92 - f https : // download . pytorch . org / whl / torch_stable . html","title":"Optional - Install romiseg:"},{"location":"Scanner/how-to/#initializing-a-database","text":"The FSDB class from the romidata module is used for data storage. A database is any folder which contains a file named romidb . To create an empty database, just create a new folder and an empty file named romidb in it.","title":"Initializing a Database"},{"location":"Scanner/how-to/#processing-pipelines","text":"","title":"Processing pipelines"},{"location":"Scanner/how-to/#testing-on-a-test-db","text":"Get the test DB from : wget https://db.romi-project.eu/models/test_db.tar.gz Extract it: tar -xvf test_db.tar.gz Test the virtual plant pipeline on a virtual scan: run-task --config Scan3D/default/segmentation2d_arabidopsis.toml PointCloud integration_tests/arabidopsis_26 --log-level DEBUG --local-scheduler This should process all dependencies to obtain a segmented \"PointCloud.ply\" !","title":"Testing on a test db"},{"location":"Scanner/how-to/#basic-usage","text":"Every task on the scanner is launched through the run - task command provided in the romiscan module. It is a wrapper for luigi , with preloaded tasks from the romiscan module. The general usage is as follows: run-task [ -h ] [ --config CONFIG ] [ --luigicmd LUIGICMD ] [ --module MODULE ] [ --local-scheduler ] [ --log-level LOG_LEVEL ] task scan CONFIG is either a file or a folder. If a file, it must be json or toml and contains the configuration of the task to run. If a folder, it will read all configuration files in json or toml format from the folder. LUIGICMD is an optional parameter specifying an alternative command for luigi . MODULE is an optional parameter for running task from external modules (see TODO). LOG_LEVEL is the level of logging. Defaults to INFO , but can be set to DEBUG to increase verbosity. task is the name of the class to run (see TODO) scan is the location of the target scan on which to process the task. It is of the form DB_LOCATION / SCAN_ID , where DB_LOCATION is a path containing the romidb marker.","title":"Basic usage"},{"location":"Scanner/how-to/#configuration-files","text":"The configuration is in the form of a dictionary, in which each key is the ID of a given task. In toml format, it reads as follows: [FirstTask] parameter1 = value1 parameter2 = value2 [SecondTask] parameter1 = value1 parameter2 = value2","title":"Configuration files"},{"location":"Scanner/how-to/#running-scans","text":"Scan is the basic task for running a task with the scanner. A sample configuration file for the (real) scanner is as follows: To see available parameters for scanner, camera, CNC, check the lettucethink module. Create a file named scanner . toml with the following text, adjusting parameters as needed for the actual configuration of the scanner. Check the lettucethink documentation for additional information. [Scan.scanner] camera_firmware = sony_wifi cnc_firmware = grbl-v1.1 gimbal_firmware = blgimbal [ Scan . scanner . scanner_args ] # These are the kwargs passed to the scanner constructor inverted = false [ Scan . scanner . camera_args ] # These are the kwargs passed to the camera constructor postview = true device_ip = 10.0.2.66 api_port = 10000 [ Scan . scanner . cnc_args ] # These are kwargs passed to the CNC constructor homing = true port = /dev/ttyUSB0 [Scan.scanner.gimbal_args] port = /dev/ttyACM1 has_tilt = false zero_pan = 145 [ Scan . scanner . camera_model ] # This is a precalibrated camera model width = 1616 height = 1080 id = 1 model = OPENCV params = [ 1120.72122223961, 1120.72122223961, 808.0, 540.0, 0.0007513494532588769, 0.0007513494532588769, 0.0, 0.0,] [ Scan . scanner . workspace ] # A volume containing the target scanned object x = [ 200, 600,] y = [ 200, 600,] z = [ -100, 300,] [ Scan . path ] # Example circular scan with 72 points: type = circular [Scan.path.args] num_points = 3 radius = 350 tilt = 0.45 # rad xc = 400 yc = 400 z = 0 [Scan.metadata] key = value # Any metadata you want to add to the scan Then, run a scan using run-task --config scanner.json Scan /path/to/db/scan_id/ --local-scheduler / path / to / db must be an existing FSDB database and scan_id must not already exist in the database. This will create the corresponding folder and fill it with images from the scan.","title":"Running scans"},{"location":"Scanner/how-to/#pipelines","text":"This is a sample configuration for the full pipeline: [Colmap] matcher = exhaustive compute_dense = false [Colmap.cli_args.feature_extractor] --ImageReader.single_camera = 1 --SiftExtraction.use_gpu = 1 [Colmap.cli_args.exhaustive_matcher] --SiftMatching.use_gpu = 1 [Colmap.cli_args.model_aligner] --robust_alignment_max_error = 10 [Masks] type = excess_green dilation = 5 binarize = true threshold = 0.0 [Voxels] voxel_size = 1.0 type = carving [PointCloud] level_set_value = 1.0 [Visualization] max_image_size = 1500 max_pcd_size = 10000 thumbnail_size = 150 pcd_source = vox2pcd mesh_source = delaunay To run the pipeline use run - task run-task --config scanner.json AnglesAndInternodes /path/to/db/scan_id/ --local-scheduler This will process all tasks up to the AnglesAndInternodes task. Every task produces a Fileset , a subdirectory in the scan directory whose name starts the same as the task name. The characters following are a hash of the configuration of the task, so that the outputs of the same task with different parameters can coexist in the same scan. Any change in the parameters will make the needed task to be recomputed with subsequent calls of run - task . Already computed tasks will be left untouched. To recompute a task, just delete the corresponding folder in the scan directory and rerun run - task .","title":"Pipelines"},{"location":"Scanner/how-to/#default-task-reference","text":"default_modules = { \"Scan\": \"romiscan.tasks.scan\", \"Clean\": \"romiscan.tasks.scan\", \"CalibrationScan\": \"romiscan.tasks.scan\", \"Colmap\": \"romiscan.tasks.colmap\", \"Undistorted\": \"romiscan.tasks.proc2d\", \"Masks\": \"romiscan.tasks.proc2d\", \"Segmentation2D\": \"romiscan.tasks.proc2d\", \"Voxels\": \"romiscan.tasks.cl\", \"PointCloud\": \"romiscan.tasks.proc3d\", \"TriangleMesh\": \"romiscan.tasks.proc3d\", \"CurveSkeleton\": \"romiscan.tasks.proc3d\", \"TreeGraph\": \"romiscan.tasks.arabidopsis\", \"AnglesAndInternodes\": \"romiscan.tasks.arabidopsis\", \"Visualization\": \"romiscan.tasks.visualization\" } Class name : Scan Module : romiscan . tasks . scan Description : A task for running a scan , real or virtual . Default upstream tasks : None Parameters : - metadata ( DictParameter ) : metadata for the scan - scanner ( DictParameter ) : scanner hardware configuration ( TODO : see hardware documentation ) - path ( DictParameter ) : scanner path configuration ( TODO : see hardware documentation ) Class name : CalibrationScan Module : romiscan . tasks . scan Description : A task for running a scan , real or virtual , with a calibration path . It is used to calibrate Colmap poses for subsequent scans . ( TODO : see calibration documentation ) Default upstream tasks : None Parameters : - metadata ( DictParameter ) : metadata for the scan - scanner ( DictParameter ) : scanner hardware configuration ( TODO : see hardware documentation ) - path ( DictParameter ) : scanner path configuration ( TODO : see hardware documentation ) - n_line : number of shots taken on the orthogonal calibration lines Class name : Clean Module : romiscan . tasks . scan Description : Cleanup a scan , keeping only the images fileset and removing all computed pipelines . Default upstream tasks : None Parameters : - no_confirm ( BoolParameter , default = False ) : do not ask for confirmation in the command prompt . Class name : Colmap Module : romiscan . tasks . colmap Description : Runs colmap on a given scan . Default upstream tasks : Scan Upstream task format : Fileset with image files Output fileset format : images . json , cameras . json , points3D . json , sparse . ply [, dense . ply ] Parameters : - matcher ( Parameter , default = exhaustive ) : either exhaustive or sequential ( TODO : see colmap documentation ) - compute_dense ( BoolParameter ) : whether to run the dense colmap to obtain a dense point cloud - cli_args ( DictParameter ) : parameters for colmap command line prompts ( TODO : see colmap documentation ) - align_pcd ( BoolParameter , default = True ) : align point cloud on calibrated or metadata poses ? - calibration_scan_id ( Parameter , default = ) : ID of the calibration scan . Class name : Undistorted Module : romiscan . tasks . proc2d Description : Undistorts images using computed intrinsic camera parameters Default upstream tasks : Scan , Colmap Upstream task format : Fileset with image files Output fileset format : Fileset with image files Class name : Masks Module : romiscan . tasks . proc2d Description : compute masks using several functions Default upstream tasks : Undistorted Upstream task format : Fileset with image files Output fileset format : Fileset with grayscale or binary image files Parameters : - type ( Parameter ) : linear , excess_green , vesselness , invert ( TODO : see segmentation documentation ) - parameters ( ListParameter ) : list of scalar parmeters , depends on type - dilation ( IntParameter ) : by how much to dilate masks if binary - binarize ( BoolParameter , default = True ) : binarize the masks - threshold ( FloatParameter , default = 0 . 0 ) : threshold for binarization - Class name : Segmentation2D Module : romiscan . tasks . proc2d Description : compute masks using trained deep learning models Default upstream tasks : Undistorted Upstream task format : Fileset with image files Output fileset format : Fileset with grayscale image files , each corresponding to a given input image and class Parameters : - query ( DictParameter ) : query to pass to upstream fileset . It filters file by metadata , e . g { channel : rgb } will process only input files such that channel metadata is equal to rgb . - labels ( Parameter ) : string of the form a,b,c such that a , b , c are the identifiers of the labels produced by the neural network - Sx , Sy ( IntParametr ) : size of the input of the neural network . Input pictures are cropped in the center to this size . - model_segmentation_name : name of .pt file that can be found at ` https : // db . romi - project . eu / models ` - Class name : Voxels Module : romiscan . tasks . cl Description : Computes a volume from backprojection of 2 D segmented images Default upstream tasks : - upstream_mask : Masks - upstream_colmap : Colmap Upstream task format : - upstream_mask : Fileset with grayscale images - upstream_colmap : Output of Colmap task Output fileset format : npz file with as many arrays as classes Parameters : - use_colmap_poses ( BoolParameter , default = True ) : Either use precomputed camera poses or output from the Colmap task - voxel_size ( FloatParameter ) : size of one side of voxels - type ( Parameter ) : carving or averaging ( TODO : See 3 D documentation ) - multiclass ( BoolParameter , default = False ) : whether input data is single class or multiclass ( e . g as an output of Segmentation2D ) - log ( BoolParameter , default = True ) , in the case of averaging type , whether to apply log when averaging values . Class name : PointCloud Module : romiscan . tasks . proc3d Description : Computes a point cloud from volumetric voxel data ( either single or multiclass ) Default upstream tasks : Voxels Upstream task format : npz file with as many 3 D array as classes Output task format : single point cloud in ply . Metadata may include label name if multiclass . Class name : TriangleMesh Module : romiscan . tasks . proc3d Description : Triangulates input point cloud . Currently ignores class data and needs only one connected component . Default upstream tasks : PointCloud Upstream task format : ply file Output task format : ply triangle mesh file Class name : CurveSkeleton Module : romiscan . tasks . proc3d Description : Creates a 3 D curve skeleton Default upstream tasks : TriangleMesh Upstream task format : ply triangle mesh Output task format : json with two entries points and lines ( TODO : precise ) Class name : TreeGraph Module : romiscan . tasks . arabidopsis Description : Creates a tree graph of the plant Default upstream tasks : CurveSkeleton Upstream task format : json Output task format : json ( TODO : precise ) Class name ; AnglesAndInternodes Module : romiscan . tasks . arabidopsis Description : Computes angles and internode Default upstream tasks : TreeGraph Upstream task format : json Output task format : json ( TODO : precise )","title":"Default task reference"},{"location":"Scanner/how-to/#visualizer","text":"","title":"Visualizer"},{"location":"Scanner/how-to/#running-a-development-server-for-the-visualizer","text":"Clone the visualizer git repository : git clone git@github.com:romi/sony_visualiseur-plantes-3d.git cd sony_visualiseur-plantes-3d Install node packages and build the pages: npm install Set the DB location using the DB_LOCATION environment variable: export DB_LOCATION = /path/to/the/db Launch the flask development server: scanner-rest-api Finally, start the frontend development server: npm start You can now access the visualizer on http://localhost:3000 .","title":"Running a development server for the visualizer"},{"location":"Scanner/how-to/#ready-to-run-docker-image","text":"See: visualizer docker image.","title":"Ready to run docker image"},{"location":"Scanner/how-to/#visualizer-api-reference","text":"","title":"Visualizer API reference"},{"location":"Scanner/how-to/#virtual-scanner","text":"","title":"Virtual scanner"},{"location":"Scanner/how-to/#basic-usage_1","text":"The virtual scanner works like an HTTP server using Blender. First, make sure you have blender ( = 2.80) installed on your machine. Then, clone the directory and access it: git clone git@github.com:romi/blender_virtual_scanner.git cd blender_virtual_scanner You can obtain sample data for the scanner here, and put it in the data folder. wget https://db.romi-project.eu/models/arabidopsis_data.zip unzip arabidopsis_data.zip -d data To use custom data, it must consist in .obj file, in which each type of organ corresponds to a distinct mesh. This mesh must have a single material whose name is the name of the organ. The data dir must contain the obj and mtl files. Additionally, background HDRI files can be downloaded from (hdri haven)[ https://hdrihaven.com/ ]. Download .hdr files and put them in the hdri folder. To start the virtual scanner, run the following script in blender: blender [ scene/texture.blend ] -b -P scan.py It will start an HTTP server on port 5000 .","title":"Basic usage"},{"location":"Scanner/how-to/#preparing-data","text":"If you have 3D models with a single mesh","title":"Preparing data"},{"location":"Scanner/how-to/#running-a-scan-with-romiscan-and-lettucethink","text":"The virtual scanner is integrated in lettucethink-python, so that it can be used directly with the Scan task in run - task . Here is a sample configuration for the virtual scanner creating 640x480 images with ground truth segmentation of organs. The server mentioned above must be running before running run - task . [Scan.scanner] camera_firmware = virtual cnc_firmware = virtual gimbal_firmware = virtual id = virtual [Scan.path] id = virtual type = circular [Scan.scanner.scanner_args] inverted = false [Scan.scanner.camera_args] width = 640 height = 480 focal = 25 render_ground_truth = true load_object = arabidopsis_0.obj?dx=10 dy=10 dz=-5 load_background = quarry_03_8k.hdr [Scan.scanner.cnc_args] [Scan.scanner.gimbal_args] [Scan.scanner.workspace] x = [ 200, 600,] y = [ 200, 600,] z = [ -100, 300,] [Scan.path.args] num_points = 10 radius = 100 tilt = 0.45 xc = 0 yc = 0 z = 50","title":"Running a scan (with romiscan and lettucethink)"},{"location":"Scanner/how-to/#running-the-pipeline-with-ground-truth-poses-without-colmap","text":"To run the pipeline without colmap and use the virtual scanner poses as a ground truth, one must use set the following parameters: [Voxels] use_colmap_poses = false [Masks] upstream_task = Scan Then the pipeline can be run as usual and colmap will not be run.","title":"Running the pipeline with ground-truth poses (without Colmap)"},{"location":"Scanner/how-to/#scanner-api-reference","text":"","title":"Scanner API reference"},{"location":"Scanner/how-to/#objects","text":"/ objects (GET): retrieve the list of obj files in the data folder that can be loaded. / load_object / object_id (GET) load the given object in the scene. Takes a translation vector as URL parameters ( dx , dy , dz )","title":"Objects"},{"location":"Scanner/how-to/#classes","text":"/ classes (GET): retrieve the list of classes.","title":"Classes"},{"location":"Scanner/how-to/#backgrounds","text":"/ backgrounds (GET): retrieve the list of hdr files in the hdri folder that can be loaded. / load_background / background_id (GET) load the given background in the scene.","title":"Backgrounds"},{"location":"Scanner/how-to/#camera","text":"/ camera_intrinsics (POST): set camera intrinsics. Keys: width , height , focal / camera_pose (POST): set camera pose. Keys: tx , ty , tz , rx , ry , rz","title":"Camera"},{"location":"Scanner/how-to/#rendering","text":"/ render (GET): gets the rendering of the scene / render_class / class_id (GET) renders the scene, with everything transparent except the given class TODO: missing endpoints httpie # Setup camera http - f post http : // localhost : 5000 / camera_intrinsics width = 1920 height = 1080 focal = 35 # Load arabidopsis_0 http get http://localhost:5000/load_object/arabidopsis_0.obj?dx=10 dy=20 dz=1 # Load old tree in the park background http get http : // 127 . 0 . 0 . 1 : 5000 / load_background / old_tree_in_city_park_8k . hdr # Move camera http - f post http : // localhost : 5000 / camera_pose tx =- 60 ty = 0 tz = 50 rx = 60 ry = 0 rz =- 90 # Render scene and download image http --download get http://localhost:5000/render # Render only leaves http --download get http://localhost:5000/render_class/Color_7","title":"Rendering"},{"location":"Scanner/reconstruct/","text":"Reconstruction Link Follow this procedure to install requirements to reconstruct plants acquired using the 3D scanner. Install requirements Link We advise to create a conda or virtual environment. A - Create a virtual environment Link virtualenv -p /usr/bin/python3.7 scan3d source reconstruct3d/bin/activate B - Create a conda environment: Link conda create -n reconstruct3d python = 3 .7 conda activate reconstruct3d Install colmap : Link Clone the sources: git clone https://github.com/colmap/colmap Install requirements: sudo apt-get install \\ git \\ cmake \\ build-essential \\ libboost-program-options-dev \\ libboost-filesystem-dev \\ libboost-graph-dev \\ libboost-regex-dev \\ libboost-system-dev \\ libboost-test-dev \\ libeigen3-dev \\ libsuitesparse-dev \\ libfreeimage-dev \\ libgoogle-glog-dev \\ libgflags-dev \\ libglew-dev \\ qtbase5-dev \\ libqt5opengl5-dev \\ libcgal-dev OPTIONAL - Fix CMake configuration scripts of CGAL Link Under Ubuntu 16.04/18.04 the CMake configuration scripts of CGAL are broken and you must also install the CGAL Qt5 package: sudo apt-get install libcgal-qt5-dev Install Ceres Solver: Link Install Ceres Solver requirements: sudo apt-get install libatlas-base-dev libsuitesparse-dev Clone the sources: git clone https://ceres-solver.googlesource.com/ceres-solver Checkout the latest tagged release: cd ceres-solver git checkout $( git describe --tags ) Compile the sources: mkdir build cd build cmake .. -DBUILD_TESTING = OFF -DBUILD_EXAMPLES = OFF make -j make install Configure and compile COLMAP: Link Clone the sources: git clone https://github.com/colmap/colmap.git Checkout the dev branch: cd colmap git checkout dev Compile and install COLMAP: mkdir build cd build To install system-wide (add sudo to make install ): cmake .. In a conda environment, do: bashcmake .. -DCMAKE_INSTALL_PREFIX= ${ CONDA_PREFIX } Compile and install COLMAP: make -j make install Troubleshooting: - Ceres_DIR = my_ceres_dir \\ - PROFILING_ENABLED = OFF \\ - TESTS_ENABLED = OFF Optional - Use NVIDIA for OpenCL Link If you want to use NVIDIA for OpenCL in the processing pipeline, install pyopencl from source, and configure it to use OpenCL 1.2 (NVIDIA does not support the default OpenCL 2.0). First, make sure you have python headers installed, on ubuntu: sudo apt install python3.7-dev opencl-headers Then install pyopencl from source, and configure it to use OpenCL 1.2: 1. Clone the sources: git clone https://github.com/inducer/pyopencl 2. Install dependencies: cd pyopencl git submodule update --init pip install pybind11 mako 3. Configure and install pyopencl to use OpenCL 1.2: ./configure.py --cl-pretend-version = 1 .2 # NVIDIA has bad OpenCL support and only provides OpenCL 1.2 python setup.py install Troubeshooting: If you have an error [...] src / wrap_cl . hpp : 57 : 10 : fatal error : CL / cl . h [...] you are missing the OpenCL headers: sudo apt install opencl-headers If you have an error [...] compiler_compat / ld : cannot find - lOpenCL [...] : bash sudo apt install ocl - icd - libopencl1 Install ROMI packages: Link Info To install directly using pip , you need ssh access to the ROMI repository on GitHub! Install romidata : pip install git+https://github.com/romi/data-storage.git@dev Install lettucethink : pip install git+https://github.com/romi/lettucethink-python@dev Install Scan3D : pip install git+https://github.com/romi/Scan3D@dev","title":"Reconstruct"},{"location":"Scanner/reconstruct/#reconstruction","text":"Follow this procedure to install requirements to reconstruct plants acquired using the 3D scanner.","title":"Reconstruction"},{"location":"Scanner/reconstruct/#install-requirements","text":"We advise to create a conda or virtual environment.","title":"Install requirements"},{"location":"Scanner/reconstruct/#a-create-a-virtual-environment","text":"virtualenv -p /usr/bin/python3.7 scan3d source reconstruct3d/bin/activate","title":"A - Create a virtual environment"},{"location":"Scanner/reconstruct/#b-create-a-conda-environment","text":"conda create -n reconstruct3d python = 3 .7 conda activate reconstruct3d","title":"B - Create a conda environment:"},{"location":"Scanner/reconstruct/#install-colmap","text":"Clone the sources: git clone https://github.com/colmap/colmap Install requirements: sudo apt-get install \\ git \\ cmake \\ build-essential \\ libboost-program-options-dev \\ libboost-filesystem-dev \\ libboost-graph-dev \\ libboost-regex-dev \\ libboost-system-dev \\ libboost-test-dev \\ libeigen3-dev \\ libsuitesparse-dev \\ libfreeimage-dev \\ libgoogle-glog-dev \\ libgflags-dev \\ libglew-dev \\ qtbase5-dev \\ libqt5opengl5-dev \\ libcgal-dev","title":"Install colmap:"},{"location":"Scanner/reconstruct/#optional-fix-cmake-configuration-scripts-of-cgal","text":"Under Ubuntu 16.04/18.04 the CMake configuration scripts of CGAL are broken and you must also install the CGAL Qt5 package: sudo apt-get install libcgal-qt5-dev","title":"OPTIONAL - Fix CMake configuration scripts of CGAL"},{"location":"Scanner/reconstruct/#install-ceres-solver","text":"Install Ceres Solver requirements: sudo apt-get install libatlas-base-dev libsuitesparse-dev Clone the sources: git clone https://ceres-solver.googlesource.com/ceres-solver Checkout the latest tagged release: cd ceres-solver git checkout $( git describe --tags ) Compile the sources: mkdir build cd build cmake .. -DBUILD_TESTING = OFF -DBUILD_EXAMPLES = OFF make -j make install","title":"Install Ceres Solver:"},{"location":"Scanner/reconstruct/#configure-and-compile-colmap","text":"Clone the sources: git clone https://github.com/colmap/colmap.git Checkout the dev branch: cd colmap git checkout dev Compile and install COLMAP: mkdir build cd build To install system-wide (add sudo to make install ): cmake .. In a conda environment, do: bashcmake .. -DCMAKE_INSTALL_PREFIX= ${ CONDA_PREFIX } Compile and install COLMAP: make -j make install Troubleshooting: - Ceres_DIR = my_ceres_dir \\ - PROFILING_ENABLED = OFF \\ - TESTS_ENABLED = OFF","title":"Configure and compile COLMAP:"},{"location":"Scanner/reconstruct/#optional-use-nvidia-for-opencl","text":"If you want to use NVIDIA for OpenCL in the processing pipeline, install pyopencl from source, and configure it to use OpenCL 1.2 (NVIDIA does not support the default OpenCL 2.0). First, make sure you have python headers installed, on ubuntu: sudo apt install python3.7-dev opencl-headers Then install pyopencl from source, and configure it to use OpenCL 1.2: 1. Clone the sources: git clone https://github.com/inducer/pyopencl 2. Install dependencies: cd pyopencl git submodule update --init pip install pybind11 mako 3. Configure and install pyopencl to use OpenCL 1.2: ./configure.py --cl-pretend-version = 1 .2 # NVIDIA has bad OpenCL support and only provides OpenCL 1.2 python setup.py install Troubeshooting: If you have an error [...] src / wrap_cl . hpp : 57 : 10 : fatal error : CL / cl . h [...] you are missing the OpenCL headers: sudo apt install opencl-headers If you have an error [...] compiler_compat / ld : cannot find - lOpenCL [...] : bash sudo apt install ocl - icd - libopencl1","title":"Optional - Use NVIDIA for OpenCL"},{"location":"Scanner/reconstruct/#install-romi-packages","text":"Info To install directly using pip , you need ssh access to the ROMI repository on GitHub! Install romidata : pip install git+https://github.com/romi/data-storage.git@dev Install lettucethink : pip install git+https://github.com/romi/lettucethink-python@dev Install Scan3D : pip install git+https://github.com/romi/Scan3D@dev","title":"Install ROMI packages:"}]}